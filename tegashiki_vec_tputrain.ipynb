{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tegashiki_vec_tputrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karino2/tegashiki/blob/master/tegashiki_vec_tputrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQph610BeO4I",
        "colab_type": "text"
      },
      "source": [
        "# Tegashiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cv0EJiZ8vi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8llPE5Qcg5nl",
        "colab_type": "code",
        "outputId": "56e6cdc8-0d8d-4b62-d86d-d23c46ef988a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.VERSION"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7hqbhF8N4A2",
        "colab_type": "code",
        "outputId": "d7ae5feb-df9a-4057-8a1f-0e32fa2308ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 06:42:18.214214 139821955409792 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhmJFiLPE4Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BEGIN_OF_SEQ = 113\n",
        "END_OF_SEQ=112\n",
        "PAD_TOKEN=0\n",
        "VOCAB_SIZE=122\n",
        "\n",
        "\n",
        "# Both train and valid\n",
        "MAX_ONE_STROKE_LEN=50\n",
        "# MAX_STROKE_NUM=22\n",
        "MAX_STROKE_NUM=27\n",
        "\n",
        "# MAX_TEX_LEN=206+2\n",
        "# +2 is bos, eos\n",
        "# +2 is bos, eos\n",
        "# MAX_TOKEN_LEN=88+2\n",
        "# MAX_TRAIN_LEN=88+2\n",
        "# MAX_TOKEN_LEN=3+2\n",
        "# MAX_TOKEN_LEN=10+2\n",
        "MAX_TOKEN_LEN=14+2\n",
        "\n",
        "\n",
        "\n",
        "NORMALIZE_MAX=2000\n",
        "\n",
        "# must match to trained dim\n",
        "EXTRACTED_FEATURE_DIM=256\n",
        "FE_DROPOUT_RATE=0.5\n",
        "FE_L2_REGULARIZATION_RATE=0.01\n",
        "\n",
        "INPUT_TYPE_POINT=1\n",
        "INPUT_TYPE_END=0\n",
        "\n",
        "# (x, y, TYPE)\n",
        "INPUT_TYPE_DIM=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRd8JqDqaig",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yO0Z_kZHeVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, RepeatVector, Reshape, Concatenate\n",
        "from tensorflow.keras.layers import TimeDistributed, Flatten, Lambda, Add, Activation, Masking, Embedding\n",
        "from tensorflow.keras.layers import AveragePooling1D, Conv1D, MaxPooling1D, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Dropout, GlobalMaxPooling1D\n",
        "from tensorflow.keras import regularizers\n",
        "import  tensorflow.keras.layers as layers\n",
        "# from tensorflow.keras.layers.embeddings import Embedding\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qCvUYX-Rh_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DROPOUT_RATE=0.9\n",
        "DROPOUT_RATE=0.5 # obsolete\n",
        "ENCODER_DROPOUT_RATE=0.1\n",
        "DECODER_DROPOUT_RATE=0.1\n",
        "L2_REGULARIZATION_RATE=1e-6\n",
        "\n",
        "FEATURE_EXTRACTER_KERNEL_SIZE=7\n",
        "\n",
        "# FILTER_SIZE=3\n",
        "# KERNEL_SIZE=8\n",
        "\n",
        "FILTER_NUM=128\n",
        "# KERNEL_SIZE=5\n",
        "DECODER_KERNEL_SIZE=12\n",
        "ENCODER_KERNEL_SIZE=5\n",
        "# 5x 5layer = 25 > max_stroke_num\n",
        "\n",
        "# large\n",
        "\n",
        "# EMBEDDING_SIZE=256\n",
        "# OT_HIDDEN=256\n",
        "# GRU_HIDDEN=256\n",
        "# ATTENTION_ENC_HIDDEN=256\n",
        "# ATTENTION_DEC_HIDDEN=256\n",
        "\n",
        "# model_small\n",
        "EMBEDDING_SIZE=32\n",
        "OT_HIDDEN=128\n",
        "GRU_HIDDEN=128\n",
        "ATTENTION_ENC_HIDDEN=64\n",
        "ATTENTION_DEC_HIDDEN=64\n",
        "\n",
        "# model_small_embed acc 0.22\n",
        "# EMBEDDING_SIZE=32\n",
        "\n",
        "# OT_HIDDEN=256\n",
        "# GRU_HIDDEN=256\n",
        "# ATTENTION_ENC_HIDDEN=256\n",
        "# ATTENTION_DEC_HIDDEN=256\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ILfiioL2pVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fe_conv1d(filternum, kernelsize, x):\n",
        "    return tf.layers.Conv1D(filternum, kernelsize, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(x)\n",
        "  \n",
        "\n",
        "def feature_extractor(input_stroke_t, is_training):\n",
        "  \"\"\"input_stroke_t shape (batch, MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)\"\"\"\n",
        "  with tf.variable_scope(\"feature_extractor\"):\n",
        "    inpshape = input_stroke_t.shape\n",
        "    x = tf.reshape(input_stroke_t, [-1, inpshape[2], inpshape[3]])\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)\n",
        "\n",
        "    x = fe_conv1d(32, FEATURE_EXTRACTER_KERNEL_SIZE, x)\n",
        "    x = tf.layers.BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, 32)\n",
        "    x = tf.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "    x = tf.layers.Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN/2, 32)\n",
        "\n",
        "    x = fe_conv1d(64, FEATURE_EXTRACTER_KERNEL_SIZE, x)\n",
        "    x = tf.layers.BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    x = tf.layers.MaxPooling1D(pool_size=2, strides=2)(x)\n",
        "    x = tf.layers.Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN/4, 64)\n",
        "\n",
        "    x = fe_conv1d(EXTRACTED_FEATURE_DIM, FEATURE_EXTRACTER_KERNEL_SIZE, x)\n",
        "    x = tf.layers.BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    x = tf.layers.Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "    x = tf.reshape(x, [-1, inpshape[1], EXTRACTED_FEATURE_DIM])\n",
        "    return x\n",
        "  \n",
        "def attention_context(ht_enc, ht_dec, maxtklen):\n",
        "  w1 = tf.layers.Dense(ATTENTION_ENC_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_enc)\n",
        "  w2 = tf.layers.Dense(ATTENTION_DEC_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_dec)\n",
        "                       \n",
        "  # w1 (sample, 276, 256)\n",
        "  # w2 (samples, 90, 256)\n",
        "\n",
        "\n",
        "  w2_widen = tf.expand_dims(w2, axis=1)\n",
        "  # (sample, 1, 90, 256)\n",
        "\n",
        "  w1_widen = tf.expand_dims(w1, axis=2)\n",
        "  # (sample, 276, 1, 256)\n",
        "\n",
        "  w1_widen_repeat = K.repeat_elements(w1_widen, rep=maxtklen, axis=2)\n",
        "  # (sample, 276, 90, 256)\n",
        "  \n",
        "  score =tf.nn.tanh(w1_widen_repeat+w2_widen)\n",
        "  prob = tf.layers.Dense(1, activation=\"softmax\", kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(score)\n",
        "  # score: (sample, 276, 90, 256)\n",
        "  # prob: (sample, 276, 90, 1)\n",
        "\n",
        "  ht_enc_repeated = K.repeat_elements(tf.expand_dims(ht_enc, axis=2), rep=maxtklen, axis=2)\n",
        "  # (sample, 276, 90, 256)\n",
        "\n",
        "  context_vec = tf.reduce_sum(prob*ht_enc_repeated, axis=1)\n",
        "  # (sample, 90, 256)\n",
        "\n",
        "  return context_vec  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGDjwa1vAs_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRANSFORMER_H = 8\n",
        "TRANSFORMER_D=64\n",
        "TRANSFORMER_D_MODEL=TRANSFORMER_H*TRANSFORMER_D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA6SA1wFcqg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def layer_norm(x):\n",
        "  \"\"\"Layer norm only for last dimension.\"\"\"\n",
        "  return tf.contrib.layers.layer_norm(inputs=x, begin_norm_axis=-1, begin_params_axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ0Ki7-VQkbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mNAN7oZ_yhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# same as tensorflow official implementation, but specify each dim for XLA\n",
        "# https://github.com/tensorflow/models/blob/master/official/transformer/model/attention_layer.py\n",
        "def split_heads(x, seqlen, num_heads=TRANSFORMER_H, one_depth=TRANSFORMER_D):\n",
        "  x = tf.reshape(x, [-1, seqlen, num_heads, one_depth])\n",
        "  return tf.transpose(x, [0, 2, 1, 3])  \n",
        "\n",
        "def multihead_attention(query, query_seq_len, y, y_seq_len, mask_bias, dropout_rate, is_training):\n",
        "  num_head = TRANSFORMER_H\n",
        "  size_per_head = TRANSFORMER_D\n",
        "  multi_q = tf.layers.Dense(num_head*size_per_head, use_bias=False)(query)\n",
        "  multi_k = tf.layers.Dense(num_head*size_per_head, use_bias=False)(y)\n",
        "  multi_v = tf.layers.Dense(num_head*size_per_head, use_bias=False)(y)\n",
        "  k_seq_len = v_seq_len = y_seq_len\n",
        "  \n",
        "  multi_q = split_heads(multi_q, query_seq_len)\n",
        "  multi_k = split_heads(multi_k, k_seq_len)\n",
        "  multi_v = split_heads(multi_v, v_seq_len)\n",
        "  \n",
        "  multi_q *= TRANSFORMER_D ** -0.5\n",
        "\n",
        "  # Calculate dot product attention\n",
        "  logits = tf.matmul(multi_q, multi_k, transpose_b=True)\n",
        "  \n",
        "  logits += mask_bias\n",
        "  \n",
        "  weights = tf.nn.softmax(logits)\n",
        "  weights = tf.layers.Dropout(dropout_rate)(weights, training=is_training)\n",
        "  attention_output = tf.matmul(weights, multi_v)\n",
        "\n",
        "  # Recombine heads --> [batch_size, num_head, query_seq_len, size_per_head]\n",
        "  attention_output = tf.transpose(attention_output, [0, 2, 1, 3]) # --> [batch, query_seq_len, num_heads, size_per_head]\n",
        "  attention_output = tf.reshape(attention_output, [-1, query_seq_len, TRANSFORMER_D_MODEL])\n",
        "  \n",
        "  attention_output = tf.layers.Dense(TRANSFORMER_D_MODEL, use_bias=False)(attention_output)\n",
        "  # [64, 22, 512]\n",
        "  \n",
        "  return attention_output  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebWn0nmkkdEg",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPP-WhrcXU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "def myembedding(input, num_classes, embedding_size, name):\n",
        "  randinitializer = lambda: tf.random_uniform([num_classes, embedding_size], -1.0, 1.0)\n",
        "  embedmat = tf.get_variable(name, initializer = randinitializer)\n",
        "  return tf.nn.embedding_lookup(embedmat, input)  \n",
        "\"\"\"\n",
        "\n",
        "# dynamic shape cause TPUEstimator export to fail...\n",
        "def myembedding(input, num_classes, embedding_size, seq_num, name):\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "    randinitializer = lambda: tf.random_uniform([num_classes, embedding_size], -0.05, 0.05)\n",
        "\n",
        "    embedmat = tf.get_variable(name, initializer = randinitializer)\n",
        "    # embedding_lookup with generated tensor (eg. tf.range) cause TFLite convert fail.\n",
        "    # return tf.nn.embedding_lookup(embedmat, input)\n",
        "    onehot = tf.one_hot(input, num_classes)\n",
        "    # batch_num, seqnum = onehot.shape[0], onehot.shape[1]    \n",
        "    # flatten_onehot = tf.reshape(onehot, [batch_num*seq_num, num_classes])\n",
        "    flatten_onehot = tf.reshape(onehot, [-1, num_classes])\n",
        "    return tf.reshape(tf.matmul(flatten_onehot, embedmat), [-1, seq_num, embedding_size])\n",
        "\n",
        "def embed_stroke(stroke_features):\n",
        "  pos_stroke = tf.range(\n",
        "            0,\n",
        "            tf.shape(stroke_features)[1],\n",
        "            delta=1,\n",
        "            dtype=tf.int32,\n",
        "            name='range')\n",
        "  # pos_stroke = tf.expand_dims(tf.expand_dims(pos_stroke, axis=1), axis=0)\n",
        "  pos_stroke = tf.expand_dims(pos_stroke, axis=0)\n",
        "  pos_stroke_embed = myembedding(pos_stroke, MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM, MAX_STROKE_NUM, \"stroke_pos_embed\")\n",
        "  # pos_stroke_embed = Embedding(MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM, input_length=MAX_STROKE_NUM)(pos_stroke)\n",
        "  \n",
        "  stroke_pos_embedded = stroke_features + tf.cast(x=pos_stroke_embed, dtype=stroke_features.dtype)\n",
        "  return stroke_pos_embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ZcbyfJnUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encConv1D(filternum, kernelsize, input):\n",
        "  return tf.layers.Conv1D(filternum, kernelsize, activation='relu', padding='same', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input)\n",
        "\n",
        "def encSelfAttenBlock_SingleHead(input, is_training):\n",
        "  context_vec = attention_context(input, input, MAX_STROKE_NUM)\n",
        "  \n",
        "  attenres = tf.contrib.layers.layer_norm(input+context_vec)\n",
        "  x = encConv1D(2048, 1, attenres)\n",
        "  x = encConv1D(512, 1, x)\n",
        "  x = SpatialDropout1D(ENCODER_DROPOUT_RATE)(x, training=is_training)\n",
        "  return tf.contrib.layers.layer_norm(attenres+x)\n",
        "\n",
        "def encOneBlock(filternum, kernelsize, dropout_rate, is_training, input):\n",
        "  x = encConv1D(filternum, kernelsize, input)\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  return SpatialDropout1D(dropout_rate)(x, training=is_training)\n",
        "\n",
        "def encoder_CNN(stroke_enc, is_training, dropout_rate=DROPOUT_RATE):\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, ENCODER_KERNEL_SIZE, dropout_rate, is_training, stroke_enc)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, ENCODER_KERNEL_SIZE, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, ENCODER_KERNEL_SIZE, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, ENCODER_KERNEL_SIZE, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, ENCODER_KERNEL_SIZE, dropout_rate, is_training, x)\n",
        "  return x\n",
        "\n",
        "def encoder_FC(stroke_enc):\n",
        "  return tf.layers.Dense(EXTRACTED_FEATURE_DIM, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(stroke_enc)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZS-DHYno5yq",
        "colab_type": "text"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC4v1nwdlzJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_to_maskbias(mask):\n",
        "  # unmasked element to by -infinity.\n",
        "  mask = tf.cast(mask, tf.float32)\n",
        "  mask_bias = (-1e9)*(1.-mask)\n",
        "  mask_bias = tf.expand_dims(tf.expand_dims(mask_bias, axis=1), axis=1)\n",
        "  # [batch, 1, 1, length]\n",
        "  return mask_bias\n",
        "\n",
        "\n",
        "\n",
        "def encSelfAttenOneBlock(input, mask_bias, is_training):\n",
        "  # input - [64,22,512]\n",
        "  attention_output =  multihead_attention(input, MAX_STROKE_NUM, input, MAX_STROKE_NUM, mask_bias, ENCODER_DROPOUT_RATE, is_training)\n",
        "  attention_output = SpatialDropout1D(ENCODER_DROPOUT_RATE)(attention_output, training=is_training)\n",
        "  attention_output = layer_norm(attention_output + input)\n",
        "  \n",
        "  intermediate_output = tf.layers.Dense(2048,activation='relu', use_bias=False)(attention_output)\n",
        "  layer_output = tf.layers.Dense(TRANSFORMER_D_MODEL,use_bias=False)(intermediate_output)\n",
        "  layer_output = SpatialDropout1D(ENCODER_DROPOUT_RATE)(layer_output, training=is_training)\n",
        "  return layer_norm(layer_output+attention_output)\n",
        "\n",
        "def encoder_SelfAttention(input, mask_bias, is_training):\n",
        "  x = tf.layers.Dense(TRANSFORMER_D_MODEL,use_bias=False)(input)\n",
        "  x = SpatialDropout1D(ENCODER_DROPOUT_RATE)(x, training=is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  x = encSelfAttenOneBlock(x, mask_bias, is_training)\n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j4GuRL5kjbj",
        "colab_type": "text"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Skx94o09S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_decoder(decoder_input_t):\n",
        "   # dec_input_embedded = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=decoder_input_t.shape[1])(decoder_input_t)\n",
        "  dec_input_embedded = myembedding(decoder_input_t, VOCAB_SIZE, EMBEDDING_SIZE, MAX_TOKEN_LEN, \"dec_embed\")\n",
        "  # (batch, 98, 256)\n",
        "  \n",
        "  dec_pos_input = tf.range(\n",
        "            0,\n",
        "            tf.shape(decoder_input_t)[1],\n",
        "            delta=1,\n",
        "            dtype=tf.int32,\n",
        "            name='range')\n",
        "  \n",
        "  # [5] -> [1, 5, 1]\n",
        "  # dec_pos_input = tf.expand_dims(tf.expand_dims(dec_pos_input, axis=1), axis=0)\n",
        "  # [5] -> [1, 5]\n",
        "  dec_pos_input = tf.expand_dims(dec_pos_input, axis=0)\n",
        "  # dec_pos_embed = Embedding(MAX_TOKEN_LEN, EMBEDDING_SIZE, input_length=MAX_TOKEN_LEN)(dec_pos_input)\n",
        "  dec_pos_embed = myembedding(dec_pos_input, MAX_TOKEN_LEN, EMBEDDING_SIZE, MAX_TOKEN_LEN, \"dec_pos_embed\")\n",
        "  \n",
        "  \n",
        "  dec_embedded = dec_input_embedded + tf.cast(x=dec_pos_embed, dtype=dec_input_embedded.dtype)\n",
        "  # [32,5,32], [1,5,1,32].\n",
        "  return dec_embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X04wiZqSqu2J",
        "colab_type": "text"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm2l5ktIUYiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dynamic shape cause TPUEstimator export to fail...\n",
        "# For transformer decoder, use the same weight for embedding and reverse-embedding\n",
        "class SharedEmbedder:\n",
        "  def __init__(self, num_classes, embeding_size=TRANSFORMER_D_MODEL,seq_num=MAX_TOKEN_LEN, name=\"dec_embed\"):\n",
        "    self.num_classes = num_classes\n",
        "    self.embedding_size = embeding_size\n",
        "    self.seq_num = seq_num\n",
        "    \n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "      randinitializer = lambda: tf.random_uniform([num_classes, embeding_size], -0.05, 0.05)\n",
        "\n",
        "      self.embedmat = tf.get_variable(name, initializer = randinitializer)\n",
        "  def embed(self, input):\n",
        "    # embedding_lookup with generated tensor (eg. tf.range) cause TFLite convert fail.\n",
        "    # return tf.nn.embedding_lookup(embedmat, input)\n",
        "    onehot = tf.one_hot(input, self.num_classes)\n",
        "    # batch_num, seqnum = onehot.shape[0], onehot.shape[1]    \n",
        "    # flatten_onehot = tf.reshape(onehot, [batch_num*seq_num, num_classes])\n",
        "    flatten_onehot = tf.reshape(onehot, [-1, self.num_classes])\n",
        "    return tf.reshape(tf.matmul(flatten_onehot, self.embedmat), [-1, self.seq_num, self.embedding_size])\n",
        "  def reverse_embed(self,x):\n",
        "    x = tf.reshape(x, [-1, self.embedding_size])\n",
        "    logits = tf.matmul(x, self.embedmat, transpose_b=True)\n",
        "\n",
        "    return tf.reshape(logits, [-1, self.seq_num, self.num_classes])    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqZUs-66Vezy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_decoder_trans(decoder_input_t):\n",
        "  embedder = SharedEmbedder(VOCAB_SIZE, TRANSFORMER_D_MODEL, MAX_TOKEN_LEN, \"dec_embed\")\n",
        "  dec_input_embedded = embedder.embed(decoder_input_t)\n",
        "  \n",
        "  dec_pos_input = tf.range(\n",
        "            0,\n",
        "            tf.shape(decoder_input_t)[1],\n",
        "            delta=1,\n",
        "            dtype=tf.int32,\n",
        "            name='range')\n",
        "  \n",
        "  # [5] -> [1, 5, 1]\n",
        "  # dec_pos_input = tf.expand_dims(tf.expand_dims(dec_pos_input, axis=1), axis=0)\n",
        "  # [5] -> [1, 5]\n",
        "  dec_pos_input = tf.expand_dims(dec_pos_input, axis=0)\n",
        "  # dec_pos_embed = Embedding(MAX_TOKEN_LEN, EMBEDDING_SIZE, input_length=MAX_TOKEN_LEN)(dec_pos_input)\n",
        "  dec_pos_embed = myembedding(dec_pos_input, MAX_TOKEN_LEN, TRANSFORMER_D_MODEL, MAX_TOKEN_LEN, \"dec_pos_embed\")\n",
        "  \n",
        "  \n",
        "  dec_embedded = dec_input_embedded + tf.cast(x=dec_pos_embed, dtype=dec_input_embedded.dtype)\n",
        "  # [32,5,32], [1,5,1,32].\n",
        "  return dec_embedded, embedder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHfcdae_qxM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mask for decoder\n",
        "def subsequent_mask_bias(size):\n",
        "  mask = tf.linalg.band_part(tf.ones([size, size], dtype=tf.float32),-1, 0)\n",
        "  mask = tf.reshape(mask, [1, 1, size, size])\n",
        "  mask_bias = (-1e9)*(1.-mask)  \n",
        "  return mask_bias\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hepUs07q1ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def decoderTransOneBlock(decoder_inputs, decoder_mask_bias, ht_enc, stroke_mask_bias, is_training):\n",
        "  ht_dec =  multihead_attention(decoder_inputs, MAX_TOKEN_LEN, decoder_inputs, MAX_TOKEN_LEN, decoder_mask_bias, DECODER_DROPOUT_RATE, is_training)\n",
        "  ht_dec = SpatialDropout1D(DECODER_DROPOUT_RATE)(ht_dec, training=is_training)\n",
        "  ht_dec = layer_norm(ht_dec + decoder_inputs)\n",
        "    \n",
        "  attention_output =  multihead_attention(ht_dec, MAX_TOKEN_LEN, ht_enc, MAX_STROKE_NUM, stroke_mask_bias, DECODER_DROPOUT_RATE, is_training)\n",
        "  attention_output = SpatialDropout1D(DECODER_DROPOUT_RATE)(attention_output, training=is_training)\n",
        "  attention_output = layer_norm(attention_output + ht_dec)\n",
        "  \n",
        "  intermediate_output = tf.layers.Dense(2048,activation='relu', use_bias=False)(attention_output)\n",
        "  layer_output = tf.layers.Dense(TRANSFORMER_D_MODEL,use_bias=False)(intermediate_output)\n",
        "  layer_output = SpatialDropout1D(DECODER_DROPOUT_RATE)(layer_output, training=is_training)\n",
        "  return layer_norm(layer_output+attention_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MTtOO58l40N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_Transformer(dec_input, ht_enc, stroke_mask_bias, is_training):\n",
        "  dec_mask_bias = subsequent_mask_bias(MAX_TOKEN_LEN)\n",
        "  \n",
        "  # Shift targets to the right, and remove the last element\n",
        "  # dec_input = tf.pad(dec_input, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]  \n",
        "    \n",
        "  ht_dec = SpatialDropout1D(DECODER_DROPOUT_RATE)(dec_input, training=is_training)\n",
        "  # ht_dec = tf.layers.Dense(TRANSFORMER_D_MODEL,use_bias=False)(dec_input)\n",
        "  \n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  ht_dec = decoderTransOneBlock(ht_dec, dec_mask_bias, ht_enc, stroke_mask_bias, is_training)\n",
        "  return ht_dec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZFZr4ED3GOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_CNN(dec_embedded, is_training):\n",
        "  x = tf.layers.Conv1D(FILTER_NUM, DECODER_KERNEL_SIZE, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_embedded)\n",
        "  # This will cause future information leak!\n",
        "  # x = tf.contrib.layers.layer_norm(x)\n",
        "  return SpatialDropout1D(DROPOUT_RATE)(x, training=is_training)\n",
        "\n",
        "def decoder_CnnWithAttentionBlock(dec_input, ht_enc, is_training):\n",
        "  x = tf.layers.Conv1D(FILTER_NUM, DECODER_KERNEL_SIZE, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_input)\n",
        "  # This will cause future information leak!\n",
        "  # x = tf.contrib.layers.layer_norm(x)\n",
        "  ht_dec = SpatialDropout1D(DROPOUT_RATE)(x, training=is_training)\n",
        "  \n",
        "  context_vec = attention_context(ht_enc, ht_dec, MAX_TOKEN_LEN)\n",
        "  \n",
        "  ht_with_cont = Concatenate()([ht_dec, context_vec])\n",
        "  pw_conved = tf.layers.Conv1D(EXTRACTED_FEATURE_DIM, 1, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_with_cont)\n",
        "  \n",
        "  return SpatialDropout1D(DROPOUT_RATE)(pw_conved, training=is_training)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAT0kxTGMXIv",
        "colab_type": "text"
      },
      "source": [
        "### create_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6vuOniWivNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_stroke_t, stroke_mask, decoder_input_t, is_training):\n",
        "  stroke_features = feature_extractor(input_stroke_t, is_training)\n",
        "  # (batch, MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM)\n",
        "  \n",
        "  stroke_embedded = embed_stroke(stroke_features)\n",
        "  dec_embedded, embedder = embed_decoder_trans(decoder_input_t)\n",
        "  \n",
        "\n",
        "  # ht_enc = stroke_pos_embedded\n",
        "  # ht_enc = encoder_CNN(stroke_embedded, is_training)\n",
        "  stroke_mask_bias = mask_to_maskbias(stroke_mask)\n",
        "  ht_enc = encoder_SelfAttention(stroke_embedded, stroke_mask_bias, is_training)\n",
        "  # ht_enc = encoder_FC(stroke_pos_embedded)\n",
        " \n",
        "  # dec_ht = decoder_CnnWithAttentionBlock(dec_embedded, ht_enc, is_training)\n",
        "  dec_ht = decoder_Transformer(dec_embedded, ht_enc, stroke_mask_bias, is_training)\n",
        "  \n",
        "  logit = embedder.reverse_embed(dec_ht)\n",
        "\n",
        "  # (batch, MAX_TOKEN_LEN, 256)\n",
        "  # ot = tf.layers.Dense(OT_HIDDEN, activation=\"tanh\", kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_ht)\n",
        "\n",
        "  # (batch, MAX_TOKEN_LEN, VOCAB_SIZE\n",
        "  # logit = TimeDistributed(tf.layers.Dense(VOCAB_SIZE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE)))(ot)\n",
        "\n",
        "  return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_UHLKNyzS9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_softmax_cross_entropy_with_mask(sparse_labels, logit, mask):\n",
        "  mask = tf.cast(mask, tf.float32)\n",
        "  mask_expands = tf.expand_dims(mask, axis=2)\n",
        "  return tf.losses.sparse_softmax_cross_entropy(sparse_labels, logit, mask_expands)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOVte5fcikPw",
        "colab_type": "text"
      },
      "source": [
        "## TPUEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmD31-JuP5Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR=\"gs://karino2-tegashiki/dataset\"\n",
        "TF_RECORD_FILE=\"{}/crohme2019_pat3_train.tfrecord.gz\".format(DATA_DIR)\n",
        "TF_VALID_RECORD_FILE=\"{}/crohme2019_pat3_valid.tfrecord.gz\".format(DATA_DIR)\n",
        "FEATURE_EXTRACTOR_DIR=\"gs://karino2-tegashiki/sym_models/fe_layersbatchnorm\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hDy2QGe01Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2_trainopfix\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encselfattn_pat2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encself_dropout01\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encself_fixatten\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encself_dropout05\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2_regufix\" # bug\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2_regufix2\" #too big\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2_regufix_reg001\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecatten_pat2_regfix_reg001_div1e5\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encself_multihead\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encself_multihead_mask2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer2\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_shared\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_selfattenonly\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_selfattenonly_mynorm\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_laynorm\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_laynorm2\"\n",
        "\n",
        "MODEL_DIR=\"gs://karino2-tegashiki/models/transformer_pat3\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DGOshq6HaxK",
        "colab_type": "code",
        "outputId": "2b1f7735-875b-4d92-be61-a9a3f9c37256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.15.22.42:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 19382300113263009),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7811747237079401413),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14613909395265631766),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2454930082553484983),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6062963715174668217),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11771525847616185236),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7943288939982895141),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12273250012425227258),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17186715124370749228),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17503349382879271389),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 3728451713596682365)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuaIiuzRA0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALID_SAMPLE_NUM=50000\n",
        "TRAIN_STEP_PER_ONCE=1000\n",
        "EVAL_BATCH_SIZE=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrhnw7yyIJIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parser(serialized_example):\n",
        "  featurelen = MAX_STROKE_NUM*MAX_ONE_STROKE_LEN\n",
        "  \n",
        "  features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features={\n",
        "      'input_x': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'input_y': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'input_type': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'decoder_input':tf.FixedLenFeature([MAX_TOKEN_LEN], tf.int64),\n",
        "      'decoder_labels':tf.FixedLenFeature([MAX_TOKEN_LEN], tf.int64)}          \n",
        "  )\n",
        "  \n",
        "  input_x, input_y, input_type = [tf.reshape(tf.cast(features[fname], tf.int32), [MAX_STROKE_NUM, MAX_ONE_STROKE_LEN]) for fname in ['input_x', 'input_y', 'input_type']]\n",
        "  one_sample_stroke = tf.stack([input_x, input_y, input_type], 2)\n",
        "  decoder_input = tf.cast(features[\"decoder_input\"], tf.int32)\n",
        "  decoder_labels = tf.cast(features[\"decoder_labels\"], tf.int32)\n",
        "  \n",
        "  return {\"input_stroke\": one_sample_stroke, \"input_decoder\": decoder_input} , decoder_labels\n",
        "\n",
        "def tpu_input_fn(params):\n",
        "  dataset = tf.data.TFRecordDataset(TF_RECORD_FILE, \"GZIP\")\n",
        "  dataset = dataset.map(parser)\n",
        "  dataset = dataset.shuffle(1000).repeat()\n",
        "  dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "  return dataset\n",
        "\n",
        "def tpu_input_fn_valid(params):\n",
        "  dataset = tf.data.TFRecordDataset(TF_VALID_RECORD_FILE, \"GZIP\")\n",
        "  dataset = dataset.map(parser)\n",
        "  dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8g3R419ZLKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metric_fn(labels, logits, predicted_classes, mask_weights):\n",
        "    \"\"\"Function to return metrics for evaluation.\"\"\"\n",
        "\n",
        "      \n",
        "    accuracy = tf.metrics.accuracy(labels=labels,\n",
        "                                   predictions=predicted_classes,\n",
        "                                   weights=mask_weights,\n",
        "                                   name=\"acc_op\")\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def extract_params(features, mode, params): \n",
        "  input_stroke = tf.feature_column.input_layer(features, params['input_stroke'])\n",
        "\n",
        "  #[MAX_STROKE_NUM, MAX_ONE_STROKE_LEN]\n",
        "  input_stroke = tf.reshape(input_stroke, shape=(-1,MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM))\n",
        "  input_for_dec= tf.feature_column.input_layer(features, params['input_for_dec'])\n",
        "  # Why I have to?\n",
        "  input_for_dec = tf.cast(input_for_dec,tf.int32)\n",
        "  \n",
        "  return (input_stroke, input_for_dec)\n",
        "  \n",
        "def tpu_model_fn(features, labels, mode, params):\n",
        "  input_stroke, input_for_dec = extract_params(features, mode, params)\n",
        "  # input_stroke, input_for_dec, maxtklen = extract_params_always_train(features, mode, params)\n",
        "  \n",
        "  # check first element of type dim.\n",
        "  stroke_mask = tf.equal(input_stroke[:, :, 0, 2], 1)\n",
        "  \n",
        "  logit = create_model(input_stroke, stroke_mask, input_for_dec, mode==tf.estimator.ModeKeys.TRAIN)\n",
        "  # maxtklen = MAX_TOKEN_LEN\n",
        "  # logit = create_model_nostroke(input_stroke, input_for_dec, maxtklen)\n",
        "  \n",
        "  \n",
        "  mask = tf.not_equal(input_for_dec, 0)\n",
        "  mask_int = tf.cast(mask, tf.int64)\n",
        "  \n",
        "  predicted_classes = tf.math.argmax(logit,axis=2)*mask_int\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {\n",
        "        # In TFLite Intepreter, this output fail for allocate tensor.\n",
        "        # \"class_ids\": predicted_classes[:, tf.newaxis],\n",
        "        \"logits\": logit,\n",
        "    }\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(mode, predictions=predictions)  \n",
        "  \n",
        "  loss = sparse_softmax_cross_entropy_with_mask(labels, logit, mask)\n",
        "  \n",
        "  loss = tf.add_n([loss] + tf.losses.get_regularization_losses())\n",
        "  # regularization_loss = tf.losses.get_regularization_loss()\n",
        "  # loss = loss+ REGULARIZATION_PENALTY_RATIO* regularization_loss\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode, loss=loss, eval_metrics=(metric_fn, [labels, logit, predicted_classes, tf.cast(mask, tf.float32)]))\n",
        "  \n",
        "  \n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer(params['learning_rate'])  \n",
        "  optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)  \n",
        "  \n",
        "  train_op = tf.contrib.training.create_train_op(loss, optimizer)\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqQguzaIp-b",
        "colab_type": "code",
        "outputId": "3ede9f85-96fa-449b-9b6b-b42f890be60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from tqdm.autonotebook import tqdm as tqdmn\n",
        "\n",
        "def get_global_step(estimator):\n",
        "  try:\n",
        "    return int(estimator.get_variable_value(\"global_step\"))\n",
        "  except ValueError:\n",
        "    return 0\n",
        "      \n",
        "def train_tpu_estimator(tpu_estimator, max_steps):\n",
        "  step = get_global_step(tpu_estimator)+TRAIN_STEP_PER_ONCE\n",
        "  while step < max_steps:\n",
        "    tpu_estimator.train(\n",
        "      input_fn = tpu_input_fn,\n",
        "      max_steps=step)\n",
        "    eval_results = tpu_estimator.evaluate(\n",
        "      input_fn=tpu_input_fn_valid,\n",
        "      steps= VALID_SAMPLE_NUM// EVAL_BATCH_SIZE)\n",
        "    print(step)\n",
        "    print(eval_results)\n",
        "    step += TRAIN_STEP_PER_ONCE\n",
        "  tpu_estimator.train(\n",
        "    input_fn = tpu_input_fn,\n",
        "    max_steps=max_steps)\n",
        "  eval_results = tpu_estimator.evaluate(\n",
        "    input_fn=tpu_input_fn_valid,\n",
        "    steps= VALID_SAMPLE_NUM// EVAL_BATCH_SIZE)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi2PuIbgHkRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wss = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=FEATURE_EXTRACTOR_DIR, vars_to_warm_start=\".*feature_extractor.*\")\n",
        "# wss = None\n",
        "cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cegj2L0MHcnb",
        "colab_type": "text"
      },
      "source": [
        "### TPUEstimator instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnSsVYTBKdJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=cluster_resolver,\n",
        "    master=None,\n",
        "    model_dir=MODEL_DIR,\n",
        "    save_checkpoints_steps=100,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=1000,\n",
        "        num_shards=8,\n",
        "        per_host_input_for_training=is_per_host\n",
        "        # per_host_input_for_training=False\n",
        "    ))\n",
        "\n",
        "tpu_estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=tpu_model_fn,\n",
        "    config=run_config,\n",
        "    export_to_tpu=False, # Conv1D cause error for TPU graph with ReadVariableOp. why?\n",
        "    params={\n",
        "        'learning_rate': 0.00009,\n",
        "#        'learning_rate': 0.001,\n",
        "        'input_stroke':tf.feature_column.numeric_column(key=\"input_stroke\", shape=(MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)),\n",
        "        'input_for_dec': tf.feature_column.numeric_column(key=\"input_decoder\", shape=(MAX_TOKEN_LEN,), dtype=tf.int32),\n",
        "    },\n",
        "    warm_start_from=wss,\n",
        "    train_batch_size=8*64,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOG5sJ6mzYHt",
        "colab_type": "text"
      },
      "source": [
        "### TPUEstimator train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzZSj5h_WG62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tpu_estimator(tpu_estimator, 600000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdozZ3XfrXH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tpu_estimator(tpu_estimator, 120100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXTLZn_NICNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxeivUCLpb8E",
        "colab_type": "text"
      },
      "source": [
        "### Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk6Cqn_gpe5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stroke_input_t = tf.placeholder(tf.float32, shape=[1, MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM], name='stroke_input')\n",
        "decoder_input_t = tf.placeholder(tf.int32, shape=[1, MAX_TOKEN_LEN], name='input_decoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FonX5-spxdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAyELPW8qpPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec_mask_bias = subsequent_mask_bias(MAX_TOKEN_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pxjkxg6rA6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec_embedded = embed_decoder(decoder_input_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSVlX8T4p51I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_bias = dec_mask_bias\n",
        "num_head = TRANSFORMER_H\n",
        "size_per_head = TRANSFORMER_D\n",
        "\n",
        "multi_q = tf.layers.Dense(num_head*size_per_head, use_bias=False)(dec_embedded)\n",
        "multi_k = tf.layers.Dense(num_head*size_per_head, use_bias=False)(dec_embedded)\n",
        "k_seq_len = v_seq_len = query_seq_len = MAX_TOKEN_LEN\n",
        "\n",
        "multi_q = split_heads(multi_q, query_seq_len)\n",
        "multi_k = split_heads(multi_k, k_seq_len)\n",
        "\n",
        "multi_q *= TRANSFORMER_D ** -0.5\n",
        "\n",
        "# Calculate dot product attention\n",
        "logits = tf.matmul(multi_q, multi_k, transpose_b=True)\n",
        "\n",
        "logits += mask_bias\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6eXvEz0rlrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.initializers.global_variables())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnrClrnjrPaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits_res = sess.run(logits, feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y98kkUhp5jw",
        "colab_type": "code",
        "outputId": "13947b43-d5d3-4f88-f439-3faa63e706e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "logits_res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUM0Q3egsSzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_v = tf.layers.Dense(num_head*size_per_head, use_bias=False)(dec_embedded)\n",
        "multi_v = split_heads(multi_v, v_seq_len)\n",
        "weights = tf.nn.softmax(logits)\n",
        "weights = tf.layers.Dropout(DECODER_DROPOUT_RATE)(weights, training=True)\n",
        "attention_output = tf.matmul(weights, multi_v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-VZJNI9sSl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_res = sess.run(weights,  feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oGrFv_rssNi",
        "colab_type": "code",
        "outputId": "954a6012-06be-4f80-d784-b3b8081bb830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBcQBvrqstx9",
        "colab_type": "code",
        "outputId": "c852a5b5-a612-47a1-cd0d-f4165b4410e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "weights_res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.55561   , 0.5555012 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3704298 , 0.3702809 , 0.3704005 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.11111618, 0.11110295, 0.11113914, ..., 0.1111182 ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1010401 , 0.10099779, 0.10102966, ..., 0.1010095 ,\n",
              "          0.10097753, 0.        ],\n",
              "         [0.09260092, 0.        , 0.0925975 , ..., 0.09258243,\n",
              "          0.        , 0.09261888]],\n",
              "\n",
              "        [[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5555763 , 0.55553484, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3703248 , 0.37044606, 0.37034026, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.11107135, 0.11109683, 0.11108082, ..., 0.11111279,\n",
              "          0.        , 0.        ],\n",
              "         [0.10098841, 0.10102233, 0.10097677, ..., 0.10102633,\n",
              "          0.10096905, 0.        ],\n",
              "         [0.09258261, 0.09260799, 0.09256972, ..., 0.09259132,\n",
              "          0.09256299, 0.09259085]],\n",
              "\n",
              "        [[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.55556357, 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3703024 , 0.37052444, 0.3702843 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.1111175 , 0.1111559 , 0.11110473, ..., 0.11110955,\n",
              "          0.        , 0.        ],\n",
              "         [0.10102261, 0.101084  , 0.10100266, ..., 0.10101076,\n",
              "          0.10098696, 0.        ],\n",
              "         [0.0925831 , 0.09263973, 0.09258328, ..., 0.09260517,\n",
              "          0.0925782 , 0.09258409]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5554828 , 0.5556283 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.37043723, 0.37027588, 0.37039804, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.11111817, 0.11106805, 0.11112203, ..., 0.11110748,\n",
              "          0.        , 0.        ],\n",
              "         [0.10100153, 0.10096477, 0.10102471, ..., 0.101014  ,\n",
              "          0.        , 0.        ],\n",
              "         [0.09260838, 0.09257042, 0.09261396, ..., 0.0925803 ,\n",
              "          0.09258466, 0.09260889]],\n",
              "\n",
              "        [[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5556627 , 0.5554485 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.37040618, 0.3703268 , 0.37037823, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.11112676, 0.11111879, 0.11110377, ..., 0.11111376,\n",
              "          0.        , 0.        ],\n",
              "         [0.10100909, 0.10097536, 0.10101866, ..., 0.10099854,\n",
              "          0.10103179, 0.        ],\n",
              "         [0.09259465, 0.09256503, 0.09261503, ..., 0.09259565,\n",
              "          0.        , 0.09258155]],\n",
              "\n",
              "        [[1.1111112 , 0.        , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.5555902 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.37032804, 0.37045166, 0.37033156, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.11112408, 0.11115   , 0.11111157, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.10102559, 0.10106815, 0.10099961, ..., 0.10099655,\n",
              "          0.10101017, 0.        ],\n",
              "         [0.09260451, 0.09264333, 0.0925912 , ..., 0.09259494,\n",
              "          0.09258964, 0.09257849]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iZNsjgts0Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_output_res = sess.run(attention_output,  feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlDbGZqWs4Oq",
        "colab_type": "code",
        "outputId": "0dd63294-07fa-433e-b96d-4005fd6e5bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_output_res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZuF4b6gs3-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_v_res = sess.run(multi_v,  feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbiZrO24tzF6",
        "colab_type": "code",
        "outputId": "477543fc-d781-4639-81ce-51ecd2b18ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multi_v_res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LE-L2UTty3F",
        "colab_type": "code",
        "outputId": "15683ff2-f60b-422b-a528-d8dc41f204f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multi_v_res[0, :, 0, :].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZHeK2p2t7gu",
        "colab_type": "code",
        "outputId": "d5b5baf1-03be-44d1-df28-11a20dde3051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5M-36bRusuS",
        "colab_type": "code",
        "outputId": "c21c1cfb-d794-4e33-f809-8a739bb3de49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weights_res[0, :, 0, :].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbwkjxPiuzPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = np.matmul(weights_res, multi_v_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyUc5PVku29-",
        "colab_type": "code",
        "outputId": "539185b9-1d49-4c3b-bda6-d4ec0b24b818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLmatHNyuU98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tmp = np.matmul(weights_res[0, :, 0, :], multi_v_res[0, :, :, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1aitHonvTfX",
        "colab_type": "code",
        "outputId": "c1c45783-0fff-4155-c1aa-52cdb8ee0185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multi_v_res[0, :, :, :].shape, weights_res[0, :, 0, :].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 12, 64), (8, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlLzEUbGvLqk",
        "colab_type": "code",
        "outputId": "e864aa16-523c-4507-935e-0baef097b2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tmp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prQuaGaywAp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_v_tmp = np.copy(multi_v_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScarbLuiwFUH",
        "colab_type": "code",
        "outputId": "42218ea8-95d0-480a-f58e-e80fd8cd524c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multi_v_tmp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNoKIkytwFEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_v_tmp[:, :, 2:, :] = 1234"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbwMWV-RwPC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res1234 = np.matmul(weights_res, multi_v_tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hgT4TSrwVAL",
        "colab_type": "code",
        "outputId": "68e7de97-3235-4c70-b837-ef037afce4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res1234.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qA69T0SwXNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_normal = np.matmul(weights_res, multi_v_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ngbBWigwZuh",
        "colab_type": "code",
        "outputId": "bf92f0b9-a747-4235-f0b4-23b455dacee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res_normal.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 12, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EbVbqV7wcYY",
        "colab_type": "code",
        "outputId": "55375dc3-3c37-46a5-a97b-d2fdd2262879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "res1234[0, :, 0, :] == res_normal[0, :, 0, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True],\n",
              "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srwHTe8-wUyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.initializers.global_variables())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQEGJbC2xE5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dec_block_input = tf.layers.Dense(TRANSFORMER_D_MODEL,use_bias=False)(dec_embedded)\n",
        "ht_dec1 =  multihead_attention(dec_block_input, MAX_TOKEN_LEN, dec_block_input, MAX_TOKEN_LEN, dec_mask_bias, DECODER_DROPOUT_RATE, True)\n",
        "# ht_dec2 = SpatialDropout1D(DECODER_DROPOUT_RATE)(ht_dec1, training=True)\n",
        "ht_dec3 = tf.contrib.layers.layer_norm(ht_dec1 + dec_block_input)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpxW8Enux50-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "block_res_1 = sess.run(ht_dec3,  feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTr97mgyx_Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "block_res_2 = sess.run(ht_dec3,  feed_dict={decoder_input_t: np.array([[BEGIN_OF_SEQ, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h274TCfPyDWB",
        "colab_type": "code",
        "outputId": "880663d5-b908-4737-a4a1-a9733cbec832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "block_res_1[0, 0, :] == block_res_2[0, 0, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAGWwIVQxEq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb0PsxzkvLXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_v_res[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg5HLlpOt7Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5m1W1BppeS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multihead_attention_logits(query, query_seq_len, y, y_seq_len, mask_bias, dropout_rate, is_training):\n",
        "  num_head = TRANSFORMER_H\n",
        "  size_per_head = TRANSFORMER_D\n",
        "  multi_q = tf.layers.Dense(num_head*size_per_head, use_bias=False)(query)\n",
        "  multi_k = tf.layers.Dense(num_head*size_per_head, use_bias=False)(y)\n",
        "  k_seq_len = v_seq_len = y_seq_len\n",
        "  \n",
        "  multi_q = split_heads(multi_q, query_seq_len)\n",
        "  multi_k = split_heads(multi_k, k_seq_len)\n",
        "  \n",
        "  multi_q *= TRANSFORMER_D ** -0.5\n",
        "\n",
        "  # Calculate dot product attention\n",
        "  logits = tf.matmul(multi_q, multi_k, transpose_b=True)\n",
        "  \n",
        "  logits += mask_bias\n",
        "  \n",
        "  multi_v = tf.layers.Dense(num_head*size_per_head, use_bias=False)(y)\n",
        "  multi_v = split_heads(multi_v, v_seq_len)\n",
        "  weights = tf.nn.softmax(logits)\n",
        "  weights = tf.layers.Dropout(dropout_rate)(weights, training=is_training)\n",
        "  attention_output = tf.matmul(weights, multi_v)\n",
        "\n",
        "  # Recombine heads --> [batch_size, num_head, query_seq_len, size_per_head]\n",
        "  attention_output = tf.transpose(attention_output, [0, 2, 1, 3]) # --> [batch, query_seq_len, num_heads, size_per_head]\n",
        "  attention_output = tf.reshape(attention_output, [-1, query_seq_len, TRANSFORMER_D_MODEL])\n",
        "  \n",
        "  attention_output = tf.layers.Dense(TRANSFORMER_D_MODEL, use_bias=False)(attention_output)\n",
        "  # [64, 22, 512]\n",
        "  \n",
        "  return attention_output  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLkRbNdKSQUS",
        "colab_type": "text"
      },
      "source": [
        "### Eval test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mm0-0qSI3rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# answer 37, 29, 34, 109, 114\n",
        "JSON_FILE=\"20190716_12013337.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvy6WSYZI56s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCaZ9FzICBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(JSON_FILE) as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHJWKP-wIBzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKCq_al_JE00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawdata = data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-IdfYmdJG25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized = np.array(data[1]).reshape(MAX_STROKE_NUM, 50, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmpk3087JNr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_stroke(stroke):\n",
        "  for i in range(len(stroke)):\n",
        "    if stroke[i][0, 2] == 1:\n",
        "      poslis = stroke[i][stroke[i][:, 2]==1]\n",
        "      plt.plot(poslis[:, 0],-poslis[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mW5zMI3JEmD",
        "colab_type": "code",
        "outputId": "47201dc5-2ded-40ef-e2b3-af0892fa1f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plot_stroke(normalized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJno3JeGJWZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_input_fn(stroke_input_arr, decoder_input_arr):\n",
        "  def predict_input(params):\n",
        "      stroke_input = tf.expand_dims(tf.constant(stroke_input_arr, dtype=tf.int32), axis=0) \n",
        "      decoder_input = tf.expand_dims(tf.constant(decoder_input_arr, dtype=tf.int32), axis=0)\n",
        "\n",
        "      return tf.data.Dataset.from_tensors({\"input_stroke\": stroke_input, \"input_decoder\": decoder_input})\n",
        "  return predict_input\n",
        "\n",
        "def predict_raw(stroke, decoder_input):\n",
        "  return next(tpu_estimator.predict(input_fn=create_input_fn(stroke, decoder_input)))['logits']\n",
        "\n",
        "def predict(stroke, decoder_input):\n",
        "  logits = predict_raw(stroke, decoder_input)\n",
        "  return [logits[i, :].argmax() for i in range(MAX_TOKEN_LEN)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGP72E6UJWMR",
        "colab_type": "code",
        "outputId": "d05a064d-3f4a-4ff2-99ba-3781f91f91d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 34, 34, 34, 37, 37, 37, 114, 114, 114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeXgcR8fJkAf",
        "colab_type": "code",
        "outputId": "2c3c8025-2247-4ac6-c795-5c7101bede62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 34, 34, 34, 34, 34, 114, 114, 114, 114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ujgOiIIk5F",
        "colab_type": "code",
        "outputId": "f9d1499e-1d26-4568-e26b-b39881b5d251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 29, 29, 29, 114, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 34, 34, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UuEINJtIkku",
        "colab_type": "code",
        "outputId": "1b7a8c49-91b3-4083-f872-46498f925897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 29, 34, 29, 114, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 109, 114, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlJYaOfTJruh",
        "colab_type": "code",
        "outputId": "c809ae15-1ff1-429f-ae1b-364b38f3d992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 29, 34, 109, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 109, 114, 114, 114, 114, 114, 114, 114, 114]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPtgiDw7HyNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zd96W1fJH0cK",
        "outputId": "56162d49-5a7c-489c-9db7-99e4c0d09ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 91, 80, 85, 85, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[91, 80, 85, 68, 31, 65, 65, 11, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqCKciaWKClB",
        "colab_type": "code",
        "outputId": "fa3d85a5-c361-4d24-aea5-1aefe61210eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 29, 34, 109, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 109, 114, 34, 75, 75, 75, 75, 75, 75]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RUlg-b7Jrc4",
        "colab_type": "code",
        "outputId": "59d230b1-2791-474b-d26f-da6a1f086f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 37, 29, 34, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 29, 34, 49, 42, 42, 0, 42, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwDfMuXMHXrg",
        "colab_type": "code",
        "outputId": "c5bfcebb-0c32-42e0-a430-4ec3a286211b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 49, 29, 34, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49, 34, 34, 49, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr297AFfHXVz",
        "colab_type": "code",
        "outputId": "62055451-f2bd-4995-85f8-93e409a798a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict(normalized,  np.array([BEGIN_OF_SEQ, 65, 49, 34, 49, 114, 0, 0, 0, 0, 0, 0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[65, 49, 34, 49, 114, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsoHNLhzJTkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f2ehJoHJTQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3amciLEZcLc",
        "colab_type": "text"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awzPGt0gZ7g4",
        "colab_type": "code",
        "outputId": "953d2acf-95e9-4061-e227-76032289891e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "!git clone https://github.com/mixuala/colab_utils"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab_utils'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (243/243), 65.93 KiB | 3.00 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbjuldjZCgnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kill_tensorboard()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAIykIDbZa7R",
        "colab_type": "code",
        "outputId": "f014847b-cd40-4155-ab60-76d294ab57fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "import os\n",
        "import colab_utils.tboard\n",
        "\n",
        "ROOT = %pwd\n",
        "colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=MODEL_DIR)\n",
        "print(MODEL_DIR)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\n",
            "calling unzip ngrok-stable-linux-amd64.zip ...\n",
            "ngrok installed. path=/content/ngrok\n",
            "status: tensorboard=False, ngrok=False\n",
            "tensorboard url= http://23aa31bb.ngrok.io\n",
            "gs://karino2-tegashiki/models/transformer_pat3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ICxlNVNMGD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def find_one_command(res_arr, word):\n",
        "  return list(filter(lambda arr: arr[4] == word, res_arr))[0]\n",
        "\n",
        "def kill_tensorboard():\n",
        "  ps_res = !ps\n",
        "  res_arr = [re.split(r' +', one) for one in ps_res[1:]]\n",
        "  # pid_ngrok = find_one_command(res_arr, \"ngrok\")[1]\n",
        "  pid_tb = find_one_command(res_arr, \"tensorboard\")[1]\n",
        "  # !kill {pid_ngrok}\n",
        "  !kill {pid_tb}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn4vHtXyMvdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kill_tensorboard()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSikVbxGMomn",
        "colab_type": "code",
        "outputId": "08b22759-0026-46c7-ee4e-d13061e04c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "!ps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "     11 ?        00:00:12 node\n",
            "     27 ?        00:00:28 jupyter-noteboo\n",
            "    116 ?        00:00:01 tail\n",
            "    190 ?        00:10:11 tensorboard\n",
            "    192 ?        00:01:07 ngrok\n",
            "   6517 ?        00:00:04 python3\n",
            "   6553 ?        00:00:00 python3\n",
            "   6563 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxwUnlu9nznX",
        "colab_type": "text"
      },
      "source": [
        "# Model Export\n",
        "\n",
        "Currently, just use the same limitation of input shape for training time to confirm conversion, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kmkD__D4lRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_if_necessary(fname):\n",
        "  if os.path.exists(fname):\n",
        "    return\n",
        "  !gsutil cp gs://karino2-tegashiki/dataset/{fname} {fname}\n",
        "\n",
        "def get_and_load(fname):\n",
        "  get_if_necessary(fname)\n",
        "  with gzip.open(fname,'rb') as f:\n",
        "    return pickle.load(f)  \n",
        "  \n",
        "def send_file(fname):\n",
        "  !gsutil cp {fname} gs://karino2-tegashiki/dataset/\n",
        "    \n",
        "def dump_and_send(obj, fname):\n",
        "  with gzip.open(fname,'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "  send_file(fname)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AydcrMfa4lB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTbfgNaYpyEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.WARN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jexQwUr0hNn",
        "colab_type": "code",
        "outputId": "0a7f6215-7389-4d40-a32a-2c77b0bea9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_STROKE_NUM*MAX_ONE_STROKE_LEN*INPUT_TYPE_DIM"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4050"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61p4JFFL0oGd",
        "colab_type": "code",
        "outputId": "5a74eec7-206d-47a1-e8ed-3223d215e26f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_STROKE_NUM,MAX_ONE_STROKE_LEN,INPUT_TYPE_DIM"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR4tBPkKn2nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_serving_input():\n",
        "  stroke_input_t = tf.placeholder(tf.int32, shape=[1, MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM], name='stroke_input')\n",
        "  decoder_input_t = tf.placeholder(tf.int32, shape=[1, MAX_TOKEN_LEN], name='input_decoder')\n",
        "\n",
        "  input_fn_recv = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
        "      \"input_stroke\": stroke_input_t,\n",
        "      \"input_decoder\": decoder_input_t\n",
        "  })\n",
        "  return input_fn_recv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gNueA9dbXiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/export_expgen_rnn_small_dropout05_fixshape\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/export_expgen_convencdec_posfc\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed2\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed_small\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_fixfutureleak\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_enc256x13dec128x5\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_plain_dechidden256_fefix\"\n",
        "\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_plain_encdecatten_pat2_trainopfix\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/transformer_laynorm\"\n",
        "\n",
        "EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/transformer_pat3\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-441T4-dn2Xv",
        "colab_type": "code",
        "outputId": "27ed87f0-f02b-40f7-e811-6f2cac8d3884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tpu_estimator.export_savedmodel(\n",
        "    export_dir_base=EXPORT_DIR,\n",
        "    serving_input_receiver_fn=create_serving_input())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'gs://karino2-tegashiki/models/exports/transformer_pat3/1567335705'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIQ7JB7Hn1x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63fQhHknRysT",
        "colab_type": "text"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USsX5jNqoFAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLYU1J3XmRbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ6aWkjNZClA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XArmlf8Jmdau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGQ5Aj4JZAAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.constant(np.arange(1, 31, dtype=np.int32),\n",
        "                shape=[2, 5, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8e-QpplZQYe",
        "colab_type": "code",
        "outputId": "6d236cea-8b47-4605-8ce2-4ce6e393d11a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "sess.run(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1,  2,  3],\n",
              "        [ 4,  5,  6],\n",
              "        [ 7,  8,  9],\n",
              "        [10, 11, 12],\n",
              "        [13, 14, 15]],\n",
              "\n",
              "       [[16, 17, 18],\n",
              "        [19, 20, 21],\n",
              "        [22, 23, 24],\n",
              "        [25, 26, 27],\n",
              "        [28, 29, 30]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4SkgsOGY_sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
        "                shape=[2, 2, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFK70M0sZInP",
        "colab_type": "code",
        "outputId": "308950ea-e76d-455b-e8f9-e4bda6de3062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "sess.run(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[13, 14, 15],\n",
              "        [16, 17, 18]],\n",
              "\n",
              "       [[19, 20, 21],\n",
              "        [22, 23, 24]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qbz2yjgZgHG",
        "colab_type": "code",
        "outputId": "834775a8-30a8-4e61-b296-7b5f8992d22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1s7ynD5ZJz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = sess.run(tf.matmul(a, b, transpose_b=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUz1zSVZm_n",
        "colab_type": "code",
        "outputId": "0b04d843-bff9-4845-a7cf-30029850191f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 5, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzvJnwHmZIXE",
        "colab_type": "code",
        "outputId": "147fbf3a-7807-45d1-d209-66f049ac53cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  86,  104],\n",
              "        [ 212,  257],\n",
              "        [ 338,  410],\n",
              "        [ 464,  563],\n",
              "        [ 590,  716]],\n",
              "\n",
              "       [[1022, 1175],\n",
              "        [1202, 1382],\n",
              "        [1382, 1589],\n",
              "        [1562, 1796],\n",
              "        [1742, 2003]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb_1tmFnn2oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submask_bias = sess.run(subsequent_mask_bias(5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPlb3F0rdxHF",
        "colab_type": "code",
        "outputId": "052d8f9e-fbbc-4315-ff20-93e799ea4501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "submask_bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[-0.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09],\n",
              "         [-0.e+00, -0.e+00, -1.e+09, -1.e+09, -1.e+09],\n",
              "         [-0.e+00, -0.e+00, -0.e+00, -1.e+09, -1.e+09],\n",
              "         [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+09],\n",
              "         [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -0.e+00]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ma93c7VeGJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res2 = sess.run(tf.matmul(a, a, transpose_b=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVtiBzrceTre",
        "colab_type": "code",
        "outputId": "b7e17574-eac2-4260-e86c-7f42632cbcb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "res2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  14,   32,   50,   68,   86],\n",
              "        [  32,   77,  122,  167,  212],\n",
              "        [  50,  122,  194,  266,  338],\n",
              "        [  68,  167,  266,  365,  464],\n",
              "        [  86,  212,  338,  464,  590]],\n",
              "\n",
              "       [[ 869, 1022, 1175, 1328, 1481],\n",
              "        [1022, 1202, 1382, 1562, 1742],\n",
              "        [1175, 1382, 1589, 1796, 2003],\n",
              "        [1328, 1562, 1796, 2030, 2264],\n",
              "        [1481, 1742, 2003, 2264, 2525]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VcRcOs3d9dK",
        "colab_type": "code",
        "outputId": "d6ce9f47-4253-42cf-9ade-d4067a95c57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "sess.run(tf.nn.softmax(res2+submask_bias))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [2.86251858e-020, 1.00000000e+000, 0.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [2.89464031e-063, 5.38018616e-032, 1.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [1.03404366e-129, 1.02256891e-086, 1.01122149e-043,\n",
              "          1.00000000e+000, 0.00000000e+000],\n",
              "         [1.30491169e-219, 6.86571609e-165, 3.61235614e-110,\n",
              "          1.90061994e-055, 1.00000000e+000]],\n",
              "\n",
              "        [[1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [6.71418429e-079, 1.00000000e+000, 0.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [1.59251852e-180, 1.26195028e-090, 1.00000000e+000,\n",
              "          0.00000000e+000, 0.00000000e+000],\n",
              "         [1.33436212e-305, 5.62577643e-204, 2.37187193e-102,\n",
              "          1.00000000e+000, 0.00000000e+000],\n",
              "         [0.00000000e+000, 0.00000000e+000, 1.98737786e-227,\n",
              "          4.45800163e-114, 1.00000000e+000]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InMfWkFtd9Px",
        "colab_type": "code",
        "outputId": "f3716a0d-dba8-4eb1-d92e-d50576a2125d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "res2+submask_bias"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 1.40000000e+01, -9.99999968e+08, -9.99999950e+08,\n",
              "          -9.99999932e+08, -9.99999914e+08],\n",
              "         [ 3.20000000e+01,  7.70000000e+01, -9.99999878e+08,\n",
              "          -9.99999833e+08, -9.99999788e+08],\n",
              "         [ 5.00000000e+01,  1.22000000e+02,  1.94000000e+02,\n",
              "          -9.99999734e+08, -9.99999662e+08],\n",
              "         [ 6.80000000e+01,  1.67000000e+02,  2.66000000e+02,\n",
              "           3.65000000e+02, -9.99999536e+08],\n",
              "         [ 8.60000000e+01,  2.12000000e+02,  3.38000000e+02,\n",
              "           4.64000000e+02,  5.90000000e+02]],\n",
              "\n",
              "        [[ 8.69000000e+02, -9.99998978e+08, -9.99998825e+08,\n",
              "          -9.99998672e+08, -9.99998519e+08],\n",
              "         [ 1.02200000e+03,  1.20200000e+03, -9.99998618e+08,\n",
              "          -9.99998438e+08, -9.99998258e+08],\n",
              "         [ 1.17500000e+03,  1.38200000e+03,  1.58900000e+03,\n",
              "          -9.99998204e+08, -9.99997997e+08],\n",
              "         [ 1.32800000e+03,  1.56200000e+03,  1.79600000e+03,\n",
              "           2.03000000e+03, -9.99997736e+08],\n",
              "         [ 1.48100000e+03,  1.74200000e+03,  2.00300000e+03,\n",
              "           2.26400000e+03,  2.52500000e+03]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpjZl2rUmkLv",
        "colab_type": "code",
        "outputId": "6f801e9f-ddce-4feb-b5c4-4f54ef9f1682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "sess.run(tf.linalg.band_part(tf.ones([7, 7], dtype=tf.float32),\n",
        "                                     -1, 0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 0., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 0., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 0., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukrXXVs1m7PK",
        "colab_type": "code",
        "outputId": "99984b61-7af1-4a53-9660-4a2ffdac126c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "sess.run(tf.reshape(tf.linalg.band_part(tf.ones([7, 7], dtype=tf.float32),\n",
        "                                     -1, 0), [1, 1, 7, 7]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 1., 1., 0., 0., 0., 0.],\n",
              "         [1., 1., 1., 1., 0., 0., 0.],\n",
              "         [1., 1., 1., 1., 1., 0., 0.],\n",
              "         [1., 1., 1., 1., 1., 1., 0.],\n",
              "         [1., 1., 1., 1., 1., 1., 1.]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IygSbDRUls9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv-rRRFIoE0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jQiJ0ISgfDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C70xVtbQgf5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1+2*(k-1)*(2^n-1) #> 500\n",
        "# 1+2*7*(2^n-1) > 500\n",
        "# 2^n-1 > 499/14\n",
        "# 2^n > 1+499/14\n",
        "math.log2(1+ (499/14.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6dcFQmRz7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1+2*(k-1)*(2^n-1) #> 500\n",
        "# 1+2*7*(2^n-1) > 500\n",
        "# 2^n-1 > 499/14\n",
        "# 2^n > 1+499/14\n",
        "math.log2(1+ (499/14.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEpUtX8FtTW0",
        "colab_type": "text"
      },
      "source": [
        " https://arxiv.org/abs/1803.01271\n",
        "\n",
        "try to cover 500 len. and attention will handle larger case.\n",
        "As paper noted, best kernel size depend on task.\n",
        "I start from k=8 because our task is somewhat similar to P-MNIST, and k=8 is best for that task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfURWmWrPOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TCN residual block in paper\n",
        "# filter_size must be the same as out_channels?\n",
        "\n",
        "# filter_size=32\n",
        "def TCNResBlock(input, layer_depth, filter_size=3, kernel_size=8, dropout_rate=0.2):\n",
        "  d = 2**layer_depth\n",
        "  x = Conv1D(filter_size, kernel_size, activation='relu', dilation_rate=d, padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input)\n",
        "  \n",
        "  # https://github.com/ychfan/tf_estimator_barebone/blob/master/common/layers.py\n",
        "  # weight norm implementation. But I use layer_norm for first trial.\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "  x = Conv1D(filter_size, kernel_size, activation='relu', dilation_rate=d, padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(x)\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  x = SpatialDropout1D(dropout_rate)(x)\n",
        "  return tf.nn.relu(x + input)\n",
        "\n",
        "def TCN(input, depth=8):\n",
        "  x = input\n",
        "  for i in range(depth):\n",
        "    x = TCNResBlock(x, i)\n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6J4SkXzHOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ifjOZ8tFO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_TCN(input_from_encoder_t):\n",
        "  conved = TCN(input_from_encoder_t)\n",
        "\n",
        "  state_for_dec = Dense(GRU_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(conved[:, -1, :])\n",
        "  \n",
        "  pooled = AveragePooling1D(10)(conved)\n",
        "  return pooled, state_for_dec\n",
        "\n",
        "def encoder_CNNRNN(input_from_encoder_t, dropout_rate=DROPOUT_RATE):\n",
        "  conved = Conv1D(32, 7, activation='relu', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input_from_encoder_t)\n",
        "  pooled = AveragePooling1D(10)(conved)\n",
        "\n",
        "  ht_enc, state_enc = GRU(GRU_HIDDEN, return_sequences=True,return_state=True, dropout=dropout_rate, recurrent_dropout=dropout_rate, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), recurrent_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(pooled)\n",
        "  return ht_enc, state_enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0uGB4tnaywO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_nostroke(input_stroke_t, decoder_input_t, maxtklen=MAX_TOKEN_LEN):\n",
        "  dec_input_embedded = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=maxtklen)(decoder_input_t)\n",
        "  # (batch, 98, 256)\n",
        "\n",
        "\n",
        "  # (sample, timestamps, htdim)\n",
        "  ht_last = GRU(GRU_HIDDEN, return_sequences=True, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), recurrent_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_input_embedded)\n",
        "\n",
        "  # (Sample, 98, 112)\n",
        "  logit = TimeDistributed(Dense(VOCAB_SIZE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE)))(ht_last)\n",
        "\n",
        "  return logit\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}