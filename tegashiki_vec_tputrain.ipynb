{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tegashiki_vec_tputrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karino2/tegashiki/blob/master/tegashiki_vec_tputrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQph610BeO4I",
        "colab_type": "text"
      },
      "source": [
        "# Tegashiki"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqrV_hoosqA7",
        "colab_type": "code",
        "outputId": "343e0702-f659-4b81-d770-f3d28db97039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# today tensorflow seems update and batchnormalization name scope is changed. I downgrade for a while\n",
        "!pip install tensorflow==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.4)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.15.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
            "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.0.1)\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cv0EJiZ8vi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8llPE5Qcg5nl",
        "colab_type": "code",
        "outputId": "2a9d731d-f454-4cf9-aedd-a4780b3f2732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.VERSION"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7hqbhF8N4A2",
        "colab_type": "code",
        "outputId": "c91e433f-8cef-40d7-f441-3612a7aba6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EktQKNqKGeHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk9LsChyKqqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_if_necessary(fname):\n",
        "  if os.path.exists(fname):\n",
        "    return\n",
        "  !gsutil cp gs://karino2-tegashiki/dataset/{fname} {fname}\n",
        "\n",
        "def get_and_load(fname):\n",
        "  get_if_necessary(fname)\n",
        "  with gzip.open(fname,'rb') as f:\n",
        "    return pickle.load(f)  \n",
        "  \n",
        "def send_file(fname):\n",
        "  !gsutil cp {fname} gs://karino2-tegashiki/dataset/\n",
        "    \n",
        "def dump_and_send(obj, fname):\n",
        "  with gzip.open(fname,'wb') as f:\n",
        "    pickle.dump(obj, f)\n",
        "  send_file(fname)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhmJFiLPE4Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BEGIN_OF_SEQ = 112\n",
        "END_OF_SEQ=113\n",
        "PAD_TOKEN=0\n",
        "\n",
        "\n",
        "# Both train and valid\n",
        "# MAX_STROKE_NUM=115\n",
        "MAX_ONE_STROKE_LEN=50\n",
        "MAX_STROKE_NUM=13\n",
        "\n",
        "# MAX_TEX_LEN=206+2\n",
        "# +2 is bos, eos\n",
        "# +2 is bos, eos\n",
        "# MAX_TOKEN_LEN=88+2\n",
        "# MAX_TRAIN_LEN=88+2\n",
        "MAX_TOKEN_LEN=3+2\n",
        "\n",
        "VOCAB_SIZE=114\n",
        "\n",
        "\n",
        "NORMALIZE_MAX=2000\n",
        "\n",
        "# must match to trained dim\n",
        "EXTRACTED_FEATURE_DIM=256\n",
        "FE_DROPOUT_RATE=0.5\n",
        "FE_L2_REGULARIZATION_RATE=0.1\n",
        "\n",
        "INPUT_TYPE_POINT=1\n",
        "INPUT_TYPE_END=0\n",
        "\n",
        "# (x, y, TYPE)\n",
        "INPUT_TYPE_DIM=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRd8JqDqaig",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yO0Z_kZHeVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, RepeatVector, Reshape, Concatenate\n",
        "from tensorflow.keras.layers import TimeDistributed, Flatten, Lambda, Add, Activation, Masking, Embedding\n",
        "from tensorflow.keras.layers import AveragePooling1D, Conv1D, MaxPooling1D, SpatialDropout1D\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, GlobalMaxPooling1D\n",
        "from tensorflow.keras import regularizers\n",
        "import  tensorflow.keras.layers as layers\n",
        "# from tensorflow.keras.layers.embeddings import Embedding\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qCvUYX-Rh_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DROPOUT_RATE=0.9\n",
        "DROPOUT_RATE=0.5\n",
        "L2_REGULARIZATION_RATE=0.1\n",
        "\n",
        "FEATURE_EXTRACTER_KERNEL_SIZE=7\n",
        "\n",
        "# FILTER_SIZE=3\n",
        "# KERNEL_SIZE=8\n",
        "\n",
        "FILTER_NUM=128\n",
        "KERNEL_SIZE=5\n",
        "\n",
        "\n",
        "# large\n",
        "\n",
        "# EMBEDDING_SIZE=256\n",
        "# OT_HIDDEN=256\n",
        "# GRU_HIDDEN=256\n",
        "# ATTENTION_ENC_HIDDEN=256\n",
        "# ATTENTION_DEC_HIDDEN=256\n",
        "\n",
        "# model_small\n",
        "EMBEDDING_SIZE=32\n",
        "OT_HIDDEN=128\n",
        "GRU_HIDDEN=128\n",
        "ATTENTION_ENC_HIDDEN=64\n",
        "ATTENTION_DEC_HIDDEN=64\n",
        "\n",
        "# model_small_embed acc 0.22\n",
        "# EMBEDDING_SIZE=32\n",
        "\n",
        "# OT_HIDDEN=256\n",
        "# GRU_HIDDEN=256\n",
        "# ATTENTION_ENC_HIDDEN=256\n",
        "# ATTENTION_DEC_HIDDEN=256\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ILfiioL2pVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_extractor(input_stroke_t, is_training_arg):\n",
        "  \"\"\"input_stroke_t shape (batch, MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)\n",
        "     output: (batch, MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM)\"\"\"\n",
        "  \n",
        "  is_training = False\n",
        "  if(is_training_arg):\n",
        "    is_training = None\n",
        "  \n",
        "  with tf.variable_scope(\"feature_extractor\"):\n",
        "    inpshape = input_stroke_t.shape\n",
        "    x = tf.reshape(input_stroke_t, [-1, inpshape[2], inpshape[3]])\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)\n",
        "\n",
        "    x = Conv1D(32, FEATURE_EXTRACTER_KERNEL_SIZE, kernel_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE))(x)\n",
        "    x = BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, 32)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN/2, 32)\n",
        "\n",
        "    x = Conv1D(64, FEATURE_EXTRACTER_KERNEL_SIZE, kernel_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE))(x)\n",
        "    x = BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    # (batch*MAX_STROKE_NUM, MAX_ONE_STROKE_LEN/4, 64)\n",
        "\n",
        "    x = Conv1D(EXTRACTED_FEATURE_DIM, 7, kernel_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(FE_L2_REGULARIZATION_RATE))(x)\n",
        "    x = BatchNormalization()(x, training=is_training)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(FE_DROPOUT_RATE)(x, training=is_training)\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "    x = tf.reshape(x, [-1, inpshape[1], EXTRACTED_FEATURE_DIM])\n",
        "    return x\n",
        "  \n",
        "def attention_context(ht_enc, ht_dec, maxtklen):\n",
        "  w1 = Dense(ATTENTION_ENC_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_enc)\n",
        "  w2 = Dense(ATTENTION_DEC_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_dec)\n",
        "  # w1 (sample, 276, 256)\n",
        "  # w2 (samples, 90, 256)\n",
        "\n",
        "\n",
        "  w2_widen = tf.expand_dims(w2, axis=1)\n",
        "  # (sample, 1, 90, 256)\n",
        "\n",
        "  w1_widen = tf.expand_dims(w1, axis=2)\n",
        "  # (sample, 276, 1, 256)\n",
        "\n",
        "  w1_widen_repeat = K.repeat_elements(w1_widen, rep=maxtklen, axis=2)\n",
        "  # (sample, 276, 90, 256)\n",
        "  \n",
        "  score =tf.nn.tanh(w1_widen_repeat+w2_widen)\n",
        "  prob = Dense(1, activation=\"softmax\", kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(score)\n",
        "  # score: (sample, 276, 90, 256)\n",
        "  # prob: (sample, 276, 90, 1)\n",
        "\n",
        "  ht_enc_repeated = K.repeat_elements(tf.expand_dims(ht_enc, axis=2), rep=maxtklen, axis=2)\n",
        "  # (sample, 276, 90, 256)\n",
        "\n",
        "  context_vec = tf.reduce_sum(prob*ht_enc_repeated, axis=1)\n",
        "  # (sample, 90, 256)\n",
        "\n",
        "  return context_vec  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebWn0nmkkdEg",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPP-WhrcXU8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "def myembedding(input, num_classes, embedding_size, name):\n",
        "  randinitializer = lambda: tf.random_uniform([num_classes, embedding_size], -1.0, 1.0)\n",
        "  embedmat = tf.get_variable(name, initializer = randinitializer)\n",
        "  return tf.nn.embedding_lookup(embedmat, input)  \n",
        "\"\"\"\n",
        "\n",
        "# dynamic shape cause TPUEstimator export to fail...\n",
        "def myembedding(input, num_classes, embedding_size, seq_num, name):\n",
        "  with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "    randinitializer = lambda: tf.random_uniform([num_classes, embedding_size], -0.05, 0.05)\n",
        "\n",
        "    embedmat = tf.get_variable(name, initializer = randinitializer)\n",
        "    # embedding_lookup with generated tensor (eg. tf.range) cause TFLite convert fail.\n",
        "    # return tf.nn.embedding_lookup(embedmat, input)\n",
        "    onehot = tf.one_hot(input, num_classes)\n",
        "    # batch_num, seqnum = onehot.shape[0], onehot.shape[1]    \n",
        "    # flatten_onehot = tf.reshape(onehot, [batch_num*seq_num, num_classes])\n",
        "    flatten_onehot = tf.reshape(onehot, [-1, num_classes])\n",
        "    return tf.reshape(tf.matmul(flatten_onehot, embedmat), [-1, seq_num, embedding_size])\n",
        "\n",
        "def embed_stroke(stroke_features):\n",
        "  pos_stroke = tf.range(\n",
        "            0,\n",
        "            tf.shape(stroke_features)[1],\n",
        "            delta=1,\n",
        "            dtype=tf.int32,\n",
        "            name='range')\n",
        "  # pos_stroke = tf.expand_dims(tf.expand_dims(pos_stroke, axis=1), axis=0)\n",
        "  pos_stroke = tf.expand_dims(pos_stroke, axis=0)\n",
        "  pos_stroke_embed = myembedding(pos_stroke, MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM, MAX_STROKE_NUM, \"stroke_pos_embed\")\n",
        "  # pos_stroke_embed = Embedding(MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM, input_length=MAX_STROKE_NUM)(pos_stroke)\n",
        "  \n",
        "  stroke_pos_embedded = stroke_features + tf.cast(x=pos_stroke_embed, dtype=stroke_features.dtype)\n",
        "  return stroke_pos_embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ZcbyfJnUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encConv1D(filternum, kernelsize, input):\n",
        "  return Conv1D(filternum, kernelsize, activation='relu', padding='same', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jGGXHdwll85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encSelfAttenBlock(input):\n",
        "  context_vec = attention_context(input, input, MAX_STROKE_NUM)\n",
        "  \n",
        "  attenres = tf.contrib.layers.layer_norm(input+context_vec)\n",
        "  x = encConv1D(2048, 1, attenres)\n",
        "  x = encConv1D(512, 1, x)\n",
        "  return tf.contrib.layers.layer_norm(attenres+x)\n",
        "\n",
        "def encoder_SelfAttention(input):\n",
        "  x = encConv1D(512, 1, input)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  x = encSelfAttenBlock(x)\n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OijzWVlf8fY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def encOneBlock(filternum, kernelsize, dropout_rate, is_training, input):\n",
        "  x = encConv1D(filternum, kernelsize, input)\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  return SpatialDropout1D(dropout_rate)(x, training=is_training)\n",
        "\n",
        "def encoder_CNN(stroke_enc, is_training, dropout_rate=DROPOUT_RATE):\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, 3, dropout_rate, is_training, stroke_enc)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, 3, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, 3, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, 3, dropout_rate, is_training, x)\n",
        "  x = encOneBlock(EXTRACTED_FEATURE_DIM*4, 3, dropout_rate, is_training, x)\n",
        "  return x\n",
        "\n",
        "def encoder_FC(stroke_enc):\n",
        "  return Dense(EXTRACTED_FEATURE_DIM, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(stroke_enc)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j4GuRL5kjbj",
        "colab_type": "text"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Skx94o09S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_decoder(decoder_input_t):\n",
        "   # dec_input_embedded = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=decoder_input_t.shape[1])(decoder_input_t)\n",
        "  dec_input_embedded = myembedding(decoder_input_t, VOCAB_SIZE, EMBEDDING_SIZE, MAX_TOKEN_LEN, \"dec_embed\")\n",
        "  # (batch, 98, 256)\n",
        "  \n",
        "  dec_pos_input = tf.range(\n",
        "            0,\n",
        "            tf.shape(decoder_input_t)[1],\n",
        "            delta=1,\n",
        "            dtype=tf.int32,\n",
        "            name='range')\n",
        "  \n",
        "  # [5] -> [1, 5, 1]\n",
        "  # dec_pos_input = tf.expand_dims(tf.expand_dims(dec_pos_input, axis=1), axis=0)\n",
        "  # [5] -> [1, 5]\n",
        "  dec_pos_input = tf.expand_dims(dec_pos_input, axis=0)\n",
        "  # dec_pos_embed = Embedding(MAX_TOKEN_LEN, EMBEDDING_SIZE, input_length=MAX_TOKEN_LEN)(dec_pos_input)\n",
        "  dec_pos_embed = myembedding(dec_pos_input, MAX_TOKEN_LEN, EMBEDDING_SIZE, MAX_TOKEN_LEN, \"dec_pos_embed\")\n",
        "  \n",
        "  \n",
        "  dec_embedded = dec_input_embedded + tf.cast(x=dec_pos_embed, dtype=dec_input_embedded.dtype)\n",
        "  # [32,5,32], [1,5,1,32].\n",
        "  return dec_embedded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZFZr4ED3GOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_CNN(dec_embedded, is_training):\n",
        "  x = Conv1D(FILTER_NUM, KERNEL_SIZE, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_embedded)\n",
        "  # This will cause future information leak!\n",
        "  # x = tf.contrib.layers.layer_norm(x)\n",
        "  return SpatialDropout1D(DROPOUT_RATE)(x, training=is_training)\n",
        "\n",
        "def decoder_CnnWithAttentionBlock(dec_input, ht_enc, is_training):\n",
        "  x = Conv1D(FILTER_NUM, KERNEL_SIZE, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_input)\n",
        "  # This will cause future information leak!\n",
        "  # x = tf.contrib.layers.layer_norm(x)\n",
        "  ht_dec = SpatialDropout1D(DROPOUT_RATE)(x, training=is_training)\n",
        "  \n",
        "  context_vec = attention_context(ht_enc, ht_dec, MAX_TOKEN_LEN)\n",
        "  \n",
        "  ht_with_cont = Concatenate()([ht_dec, context_vec])\n",
        "  pw_conved = Conv1D(EXTRACTED_FEATURE_DIM, 1, activation='relu', padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(ht_with_cont)\n",
        "  \n",
        "  return SpatialDropout1D(DROPOUT_RATE)(pw_conved, training=is_training)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvOOIwi-zo7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAT0kxTGMXIv",
        "colab_type": "text"
      },
      "source": [
        "### create_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6vuOniWivNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_stroke_t, decoder_input_t, is_training):\n",
        "  stroke_features = feature_extractor(input_stroke_t, is_training)\n",
        "  # (batch, MAX_STROKE_NUM, EXTRACTED_FEATURE_DIM)\n",
        "  \n",
        "  stroke_embedded = embed_stroke(stroke_features)\n",
        "  dec_embedded = embed_decoder(decoder_input_t)\n",
        "  \n",
        "\n",
        "  # ht_enc = stroke_pos_embedded\n",
        "  ht_enc = encoder_CNN(stroke_embedded, is_training)\n",
        "  # ht_enc = encoder_FC(stroke_pos_embedded)\n",
        " \n",
        "  dec_ht = decoder_CnnWithAttentionBlock(dec_embedded, ht_enc, is_training)\n",
        "\n",
        "  # (Sample, 98, 256)\n",
        "  ot = Dense(OT_HIDDEN, activation=\"tanh\", kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_ht)\n",
        "\n",
        "  # (Sample, 98, 112)\n",
        "  logit = TimeDistributed(Dense(VOCAB_SIZE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE)))(ot)\n",
        "\n",
        "  return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmd__CkAvFk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_UHLKNyzS9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_softmax_cross_entropy_with_mask(sparse_labels, logit, mask):\n",
        "  mask = tf.cast(mask, tf.float32)\n",
        "  mask_expands = tf.expand_dims(mask, axis=2)\n",
        "  return tf.losses.sparse_softmax_cross_entropy(sparse_labels, logit, mask_expands)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbL-ts6ClM12",
        "colab_type": "code",
        "outputId": "38257648-3d24-463b-e441-d3f4046b30cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from tqdm.autonotebook import tqdm as tqdmn"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKJMZaBZijbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOVte5fcikPw",
        "colab_type": "text"
      },
      "source": [
        "## TPUEstimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmD31-JuP5Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR=\"gs://karino2-tegashiki/dataset\"\n",
        "TF_RECORD_FILE=\"{}/crohme2019_onesupsubtwo_train.tfrecord.gz\".format(DATA_DIR)\n",
        "TF_VALID_RECORD_FILE=\"{}/crohme2019_onesupsubtwo_valid.tfrecord.gz\".format(DATA_DIR)\n",
        "FEATURE_EXTRACTOR_DIR=\"gs://karino2-tegashiki/sym_models/rnn_fdim256\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hDy2QGe01Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_myembed\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_myembed2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_myembed_smallinit\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_fixfutureleak\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_enc13x256\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convdec_noenc\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencfcdec\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_enc64x256\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_enc256x13\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_enc256x13dec128x5\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_decstacked\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_dechidden2\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_rescon\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_rescon_enc2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_rescon_declast_nores\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/convencdec_rescon_mulsqrt\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_encdecattn\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_dechidden128\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_dechidden256_decstack\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_ff1024_256\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_pwconv1024\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_pwconv1024_enc1024\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/decgru_enc1024\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/decgru_enck3x5\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/decgru_encselfattn\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encdecgru_initstate5\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/encdecgru\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru2\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_kerasembedding\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_kerasembedding2\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_kerasembedding3\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_kerasembedding4\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_dechidden256_2\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_copyfromold\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_oldfe\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_fe_trainnone\"\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_fe_traintrue\"\n",
        "\n",
        "# MODEL_DIR=\"gs://karino2-tegashiki/models/plain_gru_fe_trainnone_validfalse\"\n",
        "\n",
        "MODEL_DIR=\"gs://karino2-tegashiki/models/plain_dechidden256_fefix\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DGOshq6HaxK",
        "colab_type": "code",
        "outputId": "cb9dcb23-335a-4f01-da62-f9d49316ed0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.78.40.122:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 15877183081649198435),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3442875507846121864),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 16758205945260339298),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16149631219013271050),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1696232157709755917),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4396806348190671979),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13793511724820430888),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 17132756942820129105),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 569869664931393496),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14409767722805104094),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1152559936806509810)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuaIiuzRA0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALID_SAMPLE_NUM=23884\n",
        "TRAIN_STEP_PER_ONCE=1000\n",
        "EVAL_BATCH_SIZE=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrhnw7yyIJIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parser(serialized_example):\n",
        "  featurelen = MAX_STROKE_NUM*MAX_ONE_STROKE_LEN\n",
        "  \n",
        "  features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features={\n",
        "      'input_x': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'input_y': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'input_type': tf.FixedLenFeature([featurelen], tf.int64),\n",
        "      'decoder_input':tf.FixedLenFeature([MAX_TOKEN_LEN], tf.int64),\n",
        "      'decoder_labels':tf.FixedLenFeature([MAX_TOKEN_LEN], tf.int64)}          \n",
        "  )\n",
        "  \n",
        "  input_x, input_y, input_type = [tf.reshape(tf.cast(features[fname], tf.int32), [MAX_STROKE_NUM, MAX_ONE_STROKE_LEN]) for fname in ['input_x', 'input_y', 'input_type']]\n",
        "  one_sample_stroke = tf.stack([input_x, input_y, input_type], 2)\n",
        "  decoder_input = tf.cast(features[\"decoder_input\"], tf.int32)\n",
        "  decoder_labels = tf.cast(features[\"decoder_labels\"], tf.int32)\n",
        "  \n",
        "  return {\"input_stroke\": one_sample_stroke, \"input_decoder\": decoder_input} , decoder_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDXo3R2RGsCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tpu_input_fn(params):\n",
        "  dataset = tf.data.TFRecordDataset(TF_RECORD_FILE, \"GZIP\")\n",
        "  dataset = dataset.map(parser)\n",
        "  dataset = dataset.shuffle(1000).repeat()\n",
        "  dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "  return dataset\n",
        "\n",
        "def tpu_input_fn_valid(params):\n",
        "  dataset = tf.data.TFRecordDataset(TF_VALID_RECORD_FILE, \"GZIP\")\n",
        "  dataset = dataset.map(parser)\n",
        "  dataset = dataset.batch(params['batch_size'], drop_remainder=True)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8g3R419ZLKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metric_fn(labels, logits, predicted_classes, mask_weights):\n",
        "    \"\"\"Function to return metrics for evaluation.\"\"\"\n",
        "\n",
        "      \n",
        "    accuracy = tf.metrics.accuracy(labels=labels,\n",
        "                                   predictions=predicted_classes,\n",
        "                                   weights=mask_weights,\n",
        "                                   name=\"acc_op\")\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def extract_params(features, mode, params): \n",
        "  input_stroke = tf.feature_column.input_layer(features, params['input_stroke'])\n",
        "\n",
        "  #[MAX_STROKE_NUM, MAX_ONE_STROKE_LEN]\n",
        "  input_stroke = tf.reshape(input_stroke, shape=(-1,MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM))\n",
        "  input_for_dec= tf.feature_column.input_layer(features, params['input_for_dec'])\n",
        "  # Why I have to?\n",
        "  input_for_dec = tf.cast(input_for_dec,tf.int32)\n",
        "  \n",
        "  return (input_stroke, input_for_dec)\n",
        "  \n",
        "def tpu_model_fn(features, labels, mode, params):\n",
        "  input_stroke, input_for_dec = extract_params(features, mode, params)\n",
        "  # input_stroke, input_for_dec, maxtklen = extract_params_always_train(features, mode, params)\n",
        "  \n",
        "  logit = create_model(input_stroke, input_for_dec, mode==tf.estimator.ModeKeys.TRAIN)\n",
        "  # maxtklen = MAX_TOKEN_LEN\n",
        "  # logit = create_model_nostroke(input_stroke, input_for_dec, maxtklen)\n",
        "  \n",
        "  \n",
        "  mask = tf.not_equal(input_for_dec, 0)\n",
        "  mask_int = tf.cast(mask, tf.int64)\n",
        "  \n",
        "  predicted_classes = tf.math.argmax(logit,axis=2)*mask_int\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {\n",
        "        # In TFLite Intepreter, this output fail for allocate tensor.\n",
        "        # \"class_ids\": predicted_classes[:, tf.newaxis],\n",
        "        \"logits\": logit,\n",
        "    }\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(mode, predictions=predictions)  \n",
        "  \n",
        "  loss = sparse_softmax_cross_entropy_with_mask(labels, logit, mask)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode, loss=loss, eval_metrics=(metric_fn, [labels, logit, predicted_classes, tf.cast(mask, tf.float32)]))\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer(params['learning_rate'])  \n",
        "  optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)  \n",
        "  \n",
        "  train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(mode, loss=loss, train_op=train_op)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyqQguzaIp-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_global_step(estimator):\n",
        "  try:\n",
        "    return int(estimator.get_variable_value(\"global_step\"))\n",
        "  except ValueError:\n",
        "    return 0\n",
        "      \n",
        "def train_tpu_estimator(tpu_estimator, max_steps):\n",
        "  step = get_global_step(tpu_estimator)+TRAIN_STEP_PER_ONCE\n",
        "  while step < max_steps:\n",
        "    tpu_estimator.train(\n",
        "      input_fn = tpu_input_fn,\n",
        "      max_steps=step)\n",
        "    eval_results = tpu_estimator.evaluate(\n",
        "      input_fn=tpu_input_fn_valid,\n",
        "      steps= VALID_SAMPLE_NUM// EVAL_BATCH_SIZE)\n",
        "    print(step)\n",
        "    print(eval_results)\n",
        "    step += TRAIN_STEP_PER_ONCE\n",
        "  tpu_estimator.train(\n",
        "    input_fn = tpu_input_fn,\n",
        "    max_steps=max_steps)\n",
        "  eval_results = tpu_estimator.evaluate(\n",
        "    input_fn=tpu_input_fn_valid,\n",
        "    steps= VALID_SAMPLE_NUM// EVAL_BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi2PuIbgHkRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wss = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=FEATURE_EXTRACTOR_DIR, vars_to_warm_start=\".*feature_extractor.*\")\n",
        "# wss = None\n",
        "cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cegj2L0MHcnb",
        "colab_type": "text"
      },
      "source": [
        "### TPUEstimator instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnSsVYTBKdJW",
        "colab_type": "code",
        "outputId": "6a54e479-2734-452b-fc22-d596a4cd278f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=cluster_resolver,\n",
        "    master=None,\n",
        "    model_dir=MODEL_DIR,\n",
        "    save_checkpoints_steps=100,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=1000,\n",
        "        num_shards=8,\n",
        "        per_host_input_for_training=is_per_host\n",
        "        # per_host_input_for_training=False\n",
        "    ))\n",
        "\n",
        "tpu_estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=tpu_model_fn,\n",
        "    config=run_config,\n",
        "    export_to_tpu=False, # Conv1D cause error for TPU graph with ReadVariableOp. why?\n",
        "    params={\n",
        "        'learning_rate': 0.00009,\n",
        "#        'learning_rate': 0.001,\n",
        "        'input_stroke':tf.feature_column.numeric_column(key=\"input_stroke\", shape=(MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM)),\n",
        "        'input_for_dec': tf.feature_column.numeric_column(key=\"input_decoder\", shape=(MAX_TOKEN_LEN,), dtype=tf.int32),\n",
        "    },\n",
        "    warm_start_from=wss,\n",
        "    train_batch_size=8*32,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=8)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://karino2-tegashiki/models/plain_dechidden256_fefix', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.78.40.122:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f02310a97f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.78.40.122:8470', '_evaluation_master': 'grpc://10.78.40.122:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f02310f3d30>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOG5sJ6mzYHt",
        "colab_type": "text"
      },
      "source": [
        "### TPUEstimator train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9QhcadtOee5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzZSj5h_WG62",
        "colab_type": "code",
        "outputId": "9a74ed69-550d-41fb-8711-b8cd30d926bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_tpu_estimator(tpu_estimator, 200000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "{'accuracy': 0.5711278, 'loss': 1.861565, 'global_step': 1000}\n",
            "2000\n",
            "{'accuracy': 0.68130744, 'loss': 1.3077477, 'global_step': 2000}\n",
            "3000\n",
            "{'accuracy': 0.7230848, 'loss': 1.1025167, 'global_step': 3000}\n",
            "4000\n",
            "{'accuracy': 0.7663577, 'loss': 0.9066849, 'global_step': 4000}\n",
            "5000\n",
            "{'accuracy': 0.8120708, 'loss': 0.7281349, 'global_step': 5000}\n",
            "6000\n",
            "{'accuracy': 0.84530765, 'loss': 0.58395994, 'global_step': 6000}\n",
            "7000\n",
            "{'accuracy': 0.8712734, 'loss': 0.48963678, 'global_step': 7000}\n",
            "8000\n",
            "{'accuracy': 0.88866913, 'loss': 0.41761154, 'global_step': 8000}\n",
            "9000\n",
            "{'accuracy': 0.90359527, 'loss': 0.36803076, 'global_step': 9000}\n",
            "10000\n",
            "{'accuracy': 0.9136116, 'loss': 0.3308417, 'global_step': 10000}\n",
            "11000\n",
            "{'accuracy': 0.92059743, 'loss': 0.30576494, 'global_step': 11000}\n",
            "12000\n",
            "{'accuracy': 0.9274652, 'loss': 0.28095526, 'global_step': 12000}\n",
            "13000\n",
            "{'accuracy': 0.9324537, 'loss': 0.25528494, 'global_step': 13000}\n",
            "14000\n",
            "{'accuracy': 0.938495, 'loss': 0.23895743, 'global_step': 14000}\n",
            "15000\n",
            "{'accuracy': 0.94248974, 'loss': 0.22212538, 'global_step': 15000}\n",
            "16000\n",
            "{'accuracy': 0.9455989, 'loss': 0.21183477, 'global_step': 16000}\n",
            "17000\n",
            "{'accuracy': 0.9478226, 'loss': 0.20147091, 'global_step': 17000}\n",
            "18000\n",
            "{'accuracy': 0.9509023, 'loss': 0.19093215, 'global_step': 18000}\n",
            "19000\n",
            "{'accuracy': 0.9522601, 'loss': 0.19075647, 'global_step': 19000}\n",
            "20000\n",
            "{'accuracy': 0.9548675, 'loss': 0.18160173, 'global_step': 20000}\n",
            "21000\n",
            "{'accuracy': 0.9560186, 'loss': 0.17484424, 'global_step': 21000}\n",
            "22000\n",
            "{'accuracy': 0.9572584, 'loss': 0.16927196, 'global_step': 22000}\n",
            "23000\n",
            "{'accuracy': 0.959059, 'loss': 0.16681333, 'global_step': 23000}\n",
            "24000\n",
            "{'accuracy': 0.95938367, 'loss': 0.16479285, 'global_step': 24000}\n",
            "25000\n",
            "{'accuracy': 0.9609481, 'loss': 0.1622869, 'global_step': 25000}\n",
            "26000\n",
            "{'accuracy': 0.9619419, 'loss': 0.15461685, 'global_step': 26000}\n",
            "27000\n",
            "{'accuracy': 0.96278805, 'loss': 0.15074742, 'global_step': 27000}\n",
            "28000\n",
            "{'accuracy': 0.964136, 'loss': 0.1558848, 'global_step': 28000}\n",
            "29000\n",
            "{'accuracy': 0.9651593, 'loss': 0.14875963, 'global_step': 29000}\n",
            "30000\n",
            "{'accuracy': 0.9650609, 'loss': 0.15191105, 'global_step': 30000}\n",
            "31000\n",
            "{'accuracy': 0.9658677, 'loss': 0.14706805, 'global_step': 31000}\n",
            "32000\n",
            "{'accuracy': 0.96712714, 'loss': 0.14148521, 'global_step': 32000}\n",
            "33000\n",
            "{'accuracy': 0.9673436, 'loss': 0.1442632, 'global_step': 33000}\n",
            "34000\n",
            "{'accuracy': 0.96848494, 'loss': 0.14573161, 'global_step': 34000}\n",
            "35000\n",
            "{'accuracy': 0.96865225, 'loss': 0.14364985, 'global_step': 35000}\n",
            "36000\n",
            "{'accuracy': 0.96877027, 'loss': 0.14278397, 'global_step': 36000}\n",
            "37000\n",
            "{'accuracy': 0.96885884, 'loss': 0.14039452, 'global_step': 37000}\n",
            "38000\n",
            "{'accuracy': 0.96895725, 'loss': 0.14429244, 'global_step': 38000}\n",
            "39000\n",
            "{'accuracy': 0.9707086, 'loss': 0.14851348, 'global_step': 39000}\n",
            "40000\n",
            "{'accuracy': 0.97031504, 'loss': 0.14055087, 'global_step': 40000}\n",
            "41000\n",
            "{'accuracy': 0.9710038, 'loss': 0.14088023, 'global_step': 41000}\n",
            "42000\n",
            "{'accuracy': 0.9712596, 'loss': 0.13937813, 'global_step': 42000}\n",
            "43000\n",
            "{'accuracy': 0.9714466, 'loss': 0.13814361, 'global_step': 43000}\n",
            "44000\n",
            "{'accuracy': 0.9720763, 'loss': 0.13969488, 'global_step': 44000}\n",
            "45000\n",
            "{'accuracy': 0.9711022, 'loss': 0.1392585, 'global_step': 45000}\n",
            "46000\n",
            "{'accuracy': 0.97280437, 'loss': 0.1367673, 'global_step': 46000}\n",
            "47000\n",
            "{'accuracy': 0.97248954, 'loss': 0.13694064, 'global_step': 47000}\n",
            "48000\n",
            "{'accuracy': 0.97280437, 'loss': 0.13985191, 'global_step': 48000}\n",
            "49000\n",
            "{'accuracy': 0.97299135, 'loss': 0.13919012, 'global_step': 49000}\n",
            "50000\n",
            "{'accuracy': 0.97311926, 'loss': 0.13770694, 'global_step': 50000}\n",
            "51000\n",
            "{'accuracy': 0.9733357, 'loss': 0.13344224, 'global_step': 51000}\n",
            "52000\n",
            "{'accuracy': 0.9735128, 'loss': 0.13928778, 'global_step': 52000}\n",
            "53000\n",
            "{'accuracy': 0.9738178, 'loss': 0.13848688, 'global_step': 53000}\n",
            "54000\n",
            "{'accuracy': 0.9744377, 'loss': 0.13857296, 'global_step': 54000}\n",
            "55000\n",
            "{'accuracy': 0.9747034, 'loss': 0.13548177, 'global_step': 55000}\n",
            "56000\n",
            "{'accuracy': 0.97450656, 'loss': 0.1337612, 'global_step': 56000}\n",
            "57000\n",
            "{'accuracy': 0.97463447, 'loss': 0.1423065, 'global_step': 57000}\n",
            "58000\n",
            "{'accuracy': 0.97437865, 'loss': 0.1305797, 'global_step': 58000}\n",
            "59000\n",
            "{'accuracy': 0.97509694, 'loss': 0.12294458, 'global_step': 59000}\n",
            "60000\n",
            "{'accuracy': 0.97509694, 'loss': 0.13806212, 'global_step': 60000}\n",
            "61000\n",
            "{'accuracy': 0.9751363, 'loss': 0.13961348, 'global_step': 61000}\n",
            "62000\n",
            "{'accuracy': 0.9755495, 'loss': 0.1321385, 'global_step': 62000}\n",
            "63000\n",
            "{'accuracy': 0.9755987, 'loss': 0.13534932, 'global_step': 63000}\n",
            "64000\n",
            "{'accuracy': 0.97537243, 'loss': 0.13946468, 'global_step': 64000}\n",
            "65000\n",
            "{'accuracy': 0.9758545, 'loss': 0.13990195, 'global_step': 65000}\n",
            "66000\n",
            "{'accuracy': 0.9758939, 'loss': 0.13693653, 'global_step': 66000}\n",
            "67000\n",
            "{'accuracy': 0.9757955, 'loss': 0.13223271, 'global_step': 67000}\n",
            "68000\n",
            "{'accuracy': 0.97638583, 'loss': 0.13244234, 'global_step': 68000}\n",
            "69000\n",
            "{'accuracy': 0.97674006, 'loss': 0.13008212, 'global_step': 69000}\n",
            "70000\n",
            "{'accuracy': 0.976622, 'loss': 0.13266192, 'global_step': 70000}\n",
            "71000\n",
            "{'accuracy': 0.97623825, 'loss': 0.13269301, 'global_step': 71000}\n",
            "72000\n",
            "{'accuracy': 0.9772222, 'loss': 0.1328646, 'global_step': 72000}\n",
            "73000\n",
            "{'accuracy': 0.97674006, 'loss': 0.13168333, 'global_step': 73000}\n",
            "74000\n",
            "{'accuracy': 0.9770648, 'loss': 0.13295186, 'global_step': 74000}\n",
            "75000\n",
            "{'accuracy': 0.9768975, 'loss': 0.13119276, 'global_step': 75000}\n",
            "76000\n",
            "{'accuracy': 0.9772517, 'loss': 0.12880337, 'global_step': 76000}\n",
            "77000\n",
            "{'accuracy': 0.9772517, 'loss': 0.12566355, 'global_step': 77000}\n",
            "78000\n",
            "{'accuracy': 0.9772714, 'loss': 0.12973486, 'global_step': 78000}\n",
            "79000\n",
            "{'accuracy': 0.97733045, 'loss': 0.12748648, 'global_step': 79000}\n",
            "80000\n",
            "{'accuracy': 0.9775764, 'loss': 0.13294719, 'global_step': 80000}\n",
            "81000\n",
            "{'accuracy': 0.9777732, 'loss': 0.13598049, 'global_step': 81000}\n",
            "82000\n",
            "{'accuracy': 0.97753704, 'loss': 0.13317531, 'global_step': 82000}\n",
            "83000\n",
            "{'accuracy': 0.9776158, 'loss': 0.12796855, 'global_step': 83000}\n",
            "84000\n",
            "{'accuracy': 0.9777141, 'loss': 0.13458005, 'global_step': 84000}\n",
            "85000\n",
            "{'accuracy': 0.9773993, 'loss': 0.13286954, 'global_step': 85000}\n",
            "86000\n",
            "{'accuracy': 0.97819626, 'loss': 0.12671089, 'global_step': 86000}\n",
            "87000\n",
            "{'accuracy': 0.97786176, 'loss': 0.136457, 'global_step': 87000}\n",
            "88000\n",
            "{'accuracy': 0.97773385, 'loss': 0.1312427, 'global_step': 88000}\n",
            "89000\n",
            "{'accuracy': 0.97851115, 'loss': 0.1312701, 'global_step': 89000}\n",
            "90000\n",
            "{'accuracy': 0.9778125, 'loss': 0.13120133, 'global_step': 90000}\n",
            "91000\n",
            "{'accuracy': 0.9781077, 'loss': 0.12774472, 'global_step': 91000}\n",
            "92000\n",
            "{'accuracy': 0.9783045, 'loss': 0.12823048, 'global_step': 92000}\n",
            "93000\n",
            "{'accuracy': 0.97773385, 'loss': 0.1304656, 'global_step': 93000}\n",
            "94000\n",
            "{'accuracy': 0.9786292, 'loss': 0.12828895, 'global_step': 94000}\n",
            "95000\n",
            "{'accuracy': 0.97773385, 'loss': 0.13464898, 'global_step': 95000}\n",
            "96000\n",
            "{'accuracy': 0.9777732, 'loss': 0.1378247, 'global_step': 96000}\n",
            "97000\n",
            "{'accuracy': 0.97899324, 'loss': 0.12677968, 'global_step': 97000}\n",
            "98000\n",
            "{'accuracy': 0.97902274, 'loss': 0.13511528, 'global_step': 98000}\n",
            "99000\n",
            "{'accuracy': 0.978885, 'loss': 0.14206225, 'global_step': 99000}\n",
            "100000\n",
            "{'accuracy': 0.9794459, 'loss': 0.13055955, 'global_step': 100000}\n",
            "101000\n",
            "{'accuracy': 0.9785308, 'loss': 0.14063394, 'global_step': 101000}\n",
            "102000\n",
            "{'accuracy': 0.97959346, 'loss': 0.13069664, 'global_step': 102000}\n",
            "103000\n",
            "{'accuracy': 0.9788555, 'loss': 0.13314335, 'global_step': 103000}\n",
            "104000\n",
            "{'accuracy': 0.97931796, 'loss': 0.1348705, 'global_step': 104000}\n",
            "105000\n",
            "{'accuracy': 0.9798591, 'loss': 0.13036975, 'global_step': 105000}\n",
            "106000\n",
            "{'accuracy': 0.9796033, 'loss': 0.13044582, 'global_step': 106000}\n",
            "107000\n",
            "{'accuracy': 0.9795344, 'loss': 0.12702434, 'global_step': 107000}\n",
            "108000\n",
            "{'accuracy': 0.97969186, 'loss': 0.13377227, 'global_step': 108000}\n",
            "109000\n",
            "{'accuracy': 0.9803806, 'loss': 0.121462926, 'global_step': 109000}\n",
            "110000\n",
            "{'accuracy': 0.98011494, 'loss': 0.12925547, 'global_step': 110000}\n",
            "111000\n",
            "{'accuracy': 0.98008543, 'loss': 0.13003427, 'global_step': 111000}\n",
            "112000\n",
            "{'accuracy': 0.9804691, 'loss': 0.12509097, 'global_step': 112000}\n",
            "113000\n",
            "{'accuracy': 0.98017395, 'loss': 0.12959377, 'global_step': 113000}\n",
            "114000\n",
            "{'accuracy': 0.98057735, 'loss': 0.121061444, 'global_step': 114000}\n",
            "115000\n",
            "{'accuracy': 0.9805085, 'loss': 0.12685323, 'global_step': 115000}\n",
            "116000\n",
            "{'accuracy': 0.9801838, 'loss': 0.12964818, 'global_step': 116000}\n",
            "117000\n",
            "{'accuracy': 0.9805282, 'loss': 0.12894437, 'global_step': 117000}\n",
            "118000\n",
            "{'accuracy': 0.98079383, 'loss': 0.124448724, 'global_step': 118000}\n",
            "119000\n",
            "{'accuracy': 0.98027235, 'loss': 0.13771884, 'global_step': 119000}\n",
            "120000\n",
            "{'accuracy': 0.98102015, 'loss': 0.12933932, 'global_step': 120000}\n",
            "121000\n",
            "{'accuracy': 0.9804593, 'loss': 0.13404723, 'global_step': 121000}\n",
            "122000\n",
            "{'accuracy': 0.981089, 'loss': 0.13006002, 'global_step': 122000}\n",
            "123000\n",
            "{'accuracy': 0.98074466, 'loss': 0.123704195, 'global_step': 123000}\n",
            "124000\n",
            "{'accuracy': 0.9812071, 'loss': 0.13414857, 'global_step': 124000}\n",
            "125000\n",
            "{'accuracy': 0.98098075, 'loss': 0.13434651, 'global_step': 125000}\n",
            "126000\n",
            "{'accuracy': 0.9818368, 'loss': 0.12407769, 'global_step': 126000}\n",
            "127000\n",
            "{'accuracy': 0.9811382, 'loss': 0.12783203, 'global_step': 127000}\n",
            "128000\n",
            "{'accuracy': 0.9802527, 'loss': 0.13403818, 'global_step': 128000}\n",
            "129000\n",
            "{'accuracy': 0.9818073, 'loss': 0.13736433, 'global_step': 129000}\n",
            "130000\n",
            "{'accuracy': 0.9812464, 'loss': 0.13332708, 'global_step': 130000}\n",
            "131000\n",
            "{'accuracy': 0.9815908, 'loss': 0.12965424, 'global_step': 131000}\n",
            "132000\n",
            "{'accuracy': 0.98145306, 'loss': 0.135516, 'global_step': 132000}\n",
            "133000\n",
            "{'accuracy': 0.9810693, 'loss': 0.1317024, 'global_step': 133000}\n",
            "134000\n",
            "{'accuracy': 0.9818368, 'loss': 0.12551044, 'global_step': 134000}\n",
            "135000\n",
            "{'accuracy': 0.98109883, 'loss': 0.13230735, 'global_step': 135000}\n",
            "136000\n",
            "{'accuracy': 0.9812464, 'loss': 0.13668764, 'global_step': 136000}\n",
            "137000\n",
            "{'accuracy': 0.9812858, 'loss': 0.13158442, 'global_step': 137000}\n",
            "138000\n",
            "{'accuracy': 0.9812071, 'loss': 0.13644178, 'global_step': 138000}\n",
            "139000\n",
            "{'accuracy': 0.98129565, 'loss': 0.13515751, 'global_step': 139000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdozZ3XfrXH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tpu_estimator(tpu_estimator, 120100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwGH63NMttgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-17000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxpLJv_ts7s",
        "colab_type": "code",
        "outputId": "6dc94ec9-2a36-44bb-be63-6b98346ca41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "!gsutil ls gs://karino2-tegashiki/models/convencdec_dechidden2/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://karino2-tegashiki/models/convencdec_dechidden2/\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/checkpoint\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/events.out.tfevents.1561515743.7e6bf9321036\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/graph.pbtxt\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-13000.data-00000-of-00001\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-13000.index\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-13000.meta\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-14000.data-00000-of-00001\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-14000.index\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-14000.meta\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-15000.data-00000-of-00001\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-15000.index\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-15000.meta\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-16000.data-00000-of-00001\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-16000.index\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-16000.meta\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-17000.data-00000-of-00001\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-17000.index\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/model.ckpt-17000.meta\n",
            "gs://karino2-tegashiki/models/convencdec_dechidden2/eval/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qr5LmklhnUZ",
        "colab_type": "code",
        "outputId": "4e76d93b-8d5a-49d3-bded-954d1178690e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!gsutil cp gs://karino2-tegashiki/models/convencdec_dechidden2/checkpoint checkpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://karino2-tegashiki/models/convencdec_dechidden2/checkpoint...\n",
            "/ [1 files][  277.0 B/  277.0 B]                                                \n",
            "Operation completed over 1 objects/277.0 B.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYhFH8devun2",
        "colab_type": "code",
        "outputId": "15d2121e-7719-43db-e6c7-9d4bd4ff8a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!gsutil cp checkpoint gs://karino2-tegashiki/models/convencdec_dechidden2/checkpoint "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://checkpoint [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  230.0 B/  230.0 B]                                                \n",
            "Operation completed over 1 objects/230.0 B.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MhrVd3Hvt1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3amciLEZcLc",
        "colab_type": "text"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awzPGt0gZ7g4",
        "colab_type": "code",
        "outputId": "ffdd8ab1-1a7d-4a7f-b281-6b155143ed2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!git clone https://github.com/mixuala/colab_utils"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab_utils'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "Receiving objects:   0% (1/243)   \rReceiving objects:   1% (3/243)   \rReceiving objects:   2% (5/243)   \rReceiving objects:   3% (8/243)   \rReceiving objects:   4% (10/243)   \rReceiving objects:   5% (13/243)   \rReceiving objects:   6% (15/243)   \rReceiving objects:   7% (18/243)   \rReceiving objects:   8% (20/243)   \rReceiving objects:   9% (22/243)   \rReceiving objects:  10% (25/243)   \rReceiving objects:  11% (27/243)   \rReceiving objects:  12% (30/243)   \rReceiving objects:  13% (32/243)   \rReceiving objects:  14% (35/243)   \rReceiving objects:  15% (37/243)   \rReceiving objects:  16% (39/243)   \rReceiving objects:  17% (42/243)   \rReceiving objects:  18% (44/243)   \rReceiving objects:  19% (47/243)   \rReceiving objects:  20% (49/243)   \rReceiving objects:  21% (52/243)   \rReceiving objects:  22% (54/243)   \rReceiving objects:  23% (56/243)   \rReceiving objects:  24% (59/243)   \rReceiving objects:  25% (61/243)   \rReceiving objects:  26% (64/243)   \rReceiving objects:  27% (66/243)   \rReceiving objects:  28% (69/243)   \rReceiving objects:  29% (71/243)   \rReceiving objects:  30% (73/243)   \rReceiving objects:  31% (76/243)   \rReceiving objects:  32% (78/243)   \rReceiving objects:  33% (81/243)   \rReceiving objects:  34% (83/243)   \rReceiving objects:  35% (86/243)   \rReceiving objects:  36% (88/243)   \rReceiving objects:  37% (90/243)   \rReceiving objects:  38% (93/243)   \rReceiving objects:  39% (95/243)   \rReceiving objects:  40% (98/243)   \rReceiving objects:  41% (100/243)   \rReceiving objects:  42% (103/243)   \rReceiving objects:  43% (105/243)   \rReceiving objects:  44% (107/243)   \rReceiving objects:  45% (110/243)   \rReceiving objects:  46% (112/243)   \rReceiving objects:  47% (115/243)   \rReceiving objects:  48% (117/243)   \rremote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects:  49% (120/243)   \rReceiving objects:  50% (122/243)   \rReceiving objects:  51% (124/243)   \rReceiving objects:  52% (127/243)   \rReceiving objects:  53% (129/243)   \rReceiving objects:  54% (132/243)   \rReceiving objects:  55% (134/243)   \rReceiving objects:  56% (137/243)   \rReceiving objects:  57% (139/243)   \rReceiving objects:  58% (141/243)   \rReceiving objects:  59% (144/243)   \rReceiving objects:  60% (146/243)   \rReceiving objects:  61% (149/243)   \rReceiving objects:  62% (151/243)   \rReceiving objects:  63% (154/243)   \rReceiving objects:  64% (156/243)   \rReceiving objects:  65% (158/243)   \rReceiving objects:  66% (161/243)   \rReceiving objects:  67% (163/243)   \rReceiving objects:  68% (166/243)   \rReceiving objects:  69% (168/243)   \rReceiving objects:  70% (171/243)   \rReceiving objects:  71% (173/243)   \rReceiving objects:  72% (175/243)   \rReceiving objects:  73% (178/243)   \rReceiving objects:  74% (180/243)   \rReceiving objects:  75% (183/243)   \rReceiving objects:  76% (185/243)   \rReceiving objects:  77% (188/243)   \rReceiving objects:  78% (190/243)   \rReceiving objects:  79% (192/243)   \rReceiving objects:  80% (195/243)   \rReceiving objects:  81% (197/243)   \rReceiving objects:  82% (200/243)   \rReceiving objects:  83% (202/243)   \rReceiving objects:  84% (205/243)   \rReceiving objects:  85% (207/243)   \rReceiving objects:  86% (209/243)   \rReceiving objects:  87% (212/243)   \rReceiving objects:  88% (214/243)   \rReceiving objects:  89% (217/243)   \rReceiving objects:  90% (219/243)   \rReceiving objects:  91% (222/243)   \rReceiving objects:  92% (224/243)   \rReceiving objects:  93% (226/243)   \rReceiving objects:  94% (229/243)   \rReceiving objects:  95% (231/243)   \rReceiving objects:  96% (234/243)   \rReceiving objects:  97% (236/243)   \rReceiving objects:  98% (239/243)   \rReceiving objects:  99% (241/243)   \rReceiving objects: 100% (243/243)   \rReceiving objects: 100% (243/243), 65.93 KiB | 1.27 MiB/s, done.\n",
            "Resolving deltas:   0% (0/97)   \rResolving deltas:   1% (1/97)   \rResolving deltas:   3% (3/97)   \rResolving deltas:   7% (7/97)   \rResolving deltas:  12% (12/97)   \rResolving deltas:  14% (14/97)   \rResolving deltas:  28% (28/97)   \rResolving deltas:  29% (29/97)   \rResolving deltas:  32% (32/97)   \rResolving deltas:  54% (53/97)   \rResolving deltas:  58% (57/97)   \rResolving deltas:  60% (59/97)   \rResolving deltas: 100% (97/97)   \rResolving deltas: 100% (97/97), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbjuldjZCgnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kill_tensorboard()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAIykIDbZa7R",
        "colab_type": "code",
        "outputId": "e6eaade9-1311-4b2d-891a-155ddba5b3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "import os\n",
        "import colab_utils.tboard\n",
        "\n",
        "ROOT = %pwd\n",
        "colab_utils.tboard.launch_tensorboard(bin_dir=ROOT, log_dir=MODEL_DIR)\n",
        "print(MODEL_DIR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\n",
            "calling unzip ngrok-stable-linux-amd64.zip ...\n",
            "ngrok installed. path=/content/ngrok\n",
            "status: tensorboard=False, ngrok=False\n",
            "tensorboard url= http://1563c223.ngrok.io\n",
            "gs://karino2-tegashiki/models/plain_dechidden256_fefix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ICxlNVNMGD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def find_one_command(res_arr, word):\n",
        "  return list(filter(lambda arr: arr[4] == word, res_arr))[0]\n",
        "\n",
        "def kill_tensorboard():\n",
        "  ps_res = !ps\n",
        "  res_arr = [re.split(r' +', one) for one in ps_res[1:]]\n",
        "  # pid_ngrok = find_one_command(res_arr, \"ngrok\")[1]\n",
        "  pid_tb = find_one_command(res_arr, \"tensorboard\")[1]\n",
        "  # !kill {pid_ngrok}\n",
        "  !kill {pid_tb}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn4vHtXyMvdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kill_tensorboard()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSikVbxGMomn",
        "colab_type": "code",
        "outputId": "588bab19-0adb-4f6b-a244-0002dbe2401f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "!ps"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "      6 ?        00:00:01 node\n",
            "     21 ?        00:00:02 jupyter-noteboo\n",
            "    119 ?        00:00:00 tail\n",
            "    128 ?        00:00:06 python3\n",
            "    222 ?        00:00:00 python3\n",
            "    260 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxwUnlu9nznX",
        "colab_type": "text"
      },
      "source": [
        "# Model Export\n",
        "\n",
        "Currently, just use the same limitation of input shape for training time to confirm conversion, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTbfgNaYpyEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.WARN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jexQwUr0hNn",
        "colab_type": "code",
        "outputId": "05bdeee9-c76b-4782-a8af-bf1720676d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MAX_STROKE_NUM*MAX_ONE_STROKE_LEN*INPUT_TYPE_DIM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1950"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61p4JFFL0oGd",
        "colab_type": "code",
        "outputId": "d64a1c1b-ffbf-47c6-f69a-3a7899e28713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MAX_STROKE_NUM,MAX_ONE_STROKE_LEN,INPUT_TYPE_DIM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR4tBPkKn2nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_serving_input():\n",
        "  stroke_input_t = tf.placeholder(tf.int32, shape=[1, MAX_STROKE_NUM, MAX_ONE_STROKE_LEN, INPUT_TYPE_DIM], name='stroke_input')\n",
        "  decoder_input_t = tf.placeholder(tf.int32, shape=[1, MAX_TOKEN_LEN], name='input_decoder')\n",
        "\n",
        "  input_fn_recv = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
        "      \"input_stroke\": stroke_input_t,\n",
        "      \"input_decoder\": decoder_input_t\n",
        "  })\n",
        "  return input_fn_recv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gNueA9dbXiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/export_expgen_rnn_small_dropout05_fixshape\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/export_expgen_convencdec_posfc\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed2\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_myembed_small\"\n",
        "# EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_fixfutureleak\"\n",
        "\n",
        "EXPORT_DIR=\"gs://karino2-tegashiki/models/exports/expgen_convencdec_enc256x13dec128x5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-441T4-dn2Xv",
        "colab_type": "code",
        "outputId": "574f8f3d-6dc9-480a-bf5e-3b0153da7fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tpu_estimator.export_savedmodel(\n",
        "    export_dir_base=EXPORT_DIR,\n",
        "    serving_input_receiver_fn=create_serving_input())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'gs://karino2-tegashiki/models/exports/expgen_convencdec_enc256x13dec128x5/1561326828'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIQ7JB7Hn1x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63fQhHknRysT",
        "colab_type": "text"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jQiJ0ISgfDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C70xVtbQgf5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1+2*(k-1)*(2^n-1) #> 500\n",
        "# 1+2*7*(2^n-1) > 500\n",
        "# 2^n-1 > 499/14\n",
        "# 2^n > 1+499/14\n",
        "math.log2(1+ (499/14.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6dcFQmRz7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1+2*(k-1)*(2^n-1) #> 500\n",
        "# 1+2*7*(2^n-1) > 500\n",
        "# 2^n-1 > 499/14\n",
        "# 2^n > 1+499/14\n",
        "math.log2(1+ (499/14.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEpUtX8FtTW0",
        "colab_type": "text"
      },
      "source": [
        " https://arxiv.org/abs/1803.01271\n",
        "\n",
        "try to cover 500 len. and attention will handle larger case.\n",
        "As paper noted, best kernel size depend on task.\n",
        "I start from k=8 because our task is somewhat similar to P-MNIST, and k=8 is best for that task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfURWmWrPOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TCN residual block in paper\n",
        "# filter_size must be the same as out_channels?\n",
        "\n",
        "# filter_size=32\n",
        "def TCNResBlock(input, layer_depth, filter_size=3, kernel_size=8, dropout_rate=0.2):\n",
        "  d = 2**layer_depth\n",
        "  x = Conv1D(filter_size, kernel_size, activation='relu', dilation_rate=d, padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input)\n",
        "  \n",
        "  # https://github.com/ychfan/tf_estimator_barebone/blob/master/common/layers.py\n",
        "  # weight norm implementation. But I use layer_norm for first trial.\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  x = SpatialDropout1D(dropout_rate)(x)\n",
        "\n",
        "  x = Conv1D(filter_size, kernel_size, activation='relu', dilation_rate=d, padding='causal', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(x)\n",
        "  x = tf.contrib.layers.layer_norm(x)\n",
        "  x = SpatialDropout1D(dropout_rate)(x)\n",
        "  return tf.nn.relu(x + input)\n",
        "\n",
        "def TCN(input, depth=8):\n",
        "  x = input\n",
        "  for i in range(depth):\n",
        "    x = TCNResBlock(x, i)\n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6J4SkXzHOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ifjOZ8tFO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_TCN(input_from_encoder_t):\n",
        "  conved = TCN(input_from_encoder_t)\n",
        "\n",
        "  state_for_dec = Dense(GRU_HIDDEN, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(conved[:, -1, :])\n",
        "  \n",
        "  pooled = AveragePooling1D(10)(conved)\n",
        "  return pooled, state_for_dec\n",
        "\n",
        "def encoder_CNNRNN(input_from_encoder_t, dropout_rate=DROPOUT_RATE):\n",
        "  conved = Conv1D(32, 7, activation='relu', kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(input_from_encoder_t)\n",
        "  pooled = AveragePooling1D(10)(conved)\n",
        "\n",
        "  ht_enc, state_enc = GRU(GRU_HIDDEN, return_sequences=True,return_state=True, dropout=dropout_rate, recurrent_dropout=dropout_rate, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), recurrent_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(pooled)\n",
        "  return ht_enc, state_enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0uGB4tnaywO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_nostroke(input_stroke_t, decoder_input_t, maxtklen=MAX_TOKEN_LEN):\n",
        "  dec_input_embedded = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, input_length=maxtklen)(decoder_input_t)\n",
        "  # (batch, 98, 256)\n",
        "\n",
        "\n",
        "  # (sample, timestamps, htdim)\n",
        "  ht_last = GRU(GRU_HIDDEN, return_sequences=True, dropout=DROPOUT_RATE, recurrent_dropout=DROPOUT_RATE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), recurrent_regularizer=regularizers.l2(L2_REGULARIZATION_RATE))(dec_input_embedded)\n",
        "\n",
        "  # (Sample, 98, 112)\n",
        "  logit = TimeDistributed(Dense(VOCAB_SIZE, kernel_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), bias_regularizer=regularizers.l2(L2_REGULARIZATION_RATE), activity_regularizer=regularizers.l2(L2_REGULARIZATION_RATE)))(ht_last)\n",
        "\n",
        "  return logit\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}